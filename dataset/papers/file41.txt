Over 50 million scholarly articles have been pub- lished (Jinha, 2010), and the number of arti- cles published every year keeps increasing (Druss and Marcus, 2005;Larsen and Von Ins, 2010). Approximately half of them are biomedical pa- pers. While this repository of human knowledge abounds with useful information that may unlock new, promising research directions or provide con- clusive evidence about phenomena, it has become increasingly difficult to take advantage of all avail- able information due to its sheer amount. There- fore, a technology that can assist a user to quickly locate the information of interest is highly desired, as it may reduce the time required to locate rele- vant information.When researchers search for previous literature, for example, they often skim through abstracts in order to quickly check whether the papers match their criteria of interest. This process is easier when abstracts are structured, i.e., the text in an abstract is divided into semantic headings such as objective, method, result, and conclusion. How- ever, a significant portion of published paper ab- stracts is unstructured, which makes it more diffi- cult to quickly access the information of interest. Therefore, classifying each sentence of an abstract to an appropriate heading can significantly reduce time to locate the desired information.We call this the sequential sentence classifica- tion task, in order to distinguish it from general text classification or sentence classification that does not have any context. Besides aiding humans, this task may also be useful for automatic text summarization, information extraction, and infor- mation retrieval.In this paper, we present a system based on ANNs for the sequential sentence classification task. Our model makes use of both token and character embeddings for classifying sentences, and has a sequence optimization layer that is learned jointly with other components of the model. We evaluate our model on the NICTA- PIBOSO dataset as well as a new dataset we com- piled based on the PubMed database.2 Related Work * These authors contributed equally to this work.Existing systems for sequential sentence clas- sification are mostly based on naive Bayes (NB) ( Ruch et al., 2007;Huang et al., 2013), support vector machines (SVMs) (McKnight and Srinivasan, 2003;Yamamoto and Takagi, 2005;Hirohata et al., 2008), Hidden Markov models (HMMs) ( Lin et al., 2006), and conditional ran- dom fields (CRFs) (Kim et al., 2011;Hassanzadeh et al., 2014;Hirohata et al., 2008). They often require numerous hand-engineered features based on lexical (bag-of-words, n-grams, dic- tionaries, cue words), semantic (synonyms, hy- ponyms), structural (part-of-speech tags, head- ings), and sequential (sentence position, surround- ing features) information.On the other hand, recent approaches to nat- ural language processing (NLP) based on artifi- cial neural networks (ANNs) do not require man- ual features, as they are trained to automatically learn features based on word as well as charac- ter embeddings. Moreover, ANN-based models have achieved state-of-the-art results on various NLP tasks. For short-text classification, many ANN models use word embeddings (Socher et al., 2013;Kim, 2014;Kalchbrenner et al., 2014), and most recent works are based on character embed- dings ( Zhang et al., 2015;Conneau et al., 2016;Xiao and Cho, 2016). Dos Santos and Gatti (2014) use both word and character embeddings.However, most existing works using ANNs for short-text classification do not use any context. This is in contrast with sequential sentence classi- fication, where each sentence in a text is classified taking into account its context. The context uti- lized for the classification could be the surround- ing sentences or possibly the whole text. One ex- ception is a recent work on dialog act classifica- tion ( Lee and Dernoncourt, 2016), where each ut- terance in a dialog is classified into its dialog act, but only the preceding utterances were used, as the system was designed with real-time applications in mind.a 1 a 2 a n-1 a j a n In the following, we denote scalars in italic low- ercase (e.g., k, b f ), vectors in bold lowercase (e.g., s, x i ), and matrices in italic uppercase (e.g., W f ) symbols. We use the colon notations x i:j and v i:j to denote the sequences of scalarsToken embeddings are a direct mapping V T (·) from token to vector, which can be pre-trained on large unlabeled datasets using programs such as word2vec ( Mikolov et al., 2013b;Mikolov et al., 2013a;Mikolov et al., 2013c) or GloVe ( Pennington et al., 2014). Character embeddings are also defined in an analogous manner, as a direct map- ping V C (·) from character to vector.Our ANN model (Figure 1) consists of three com- ponents: a hybrid token embedding layer, a sen- tence label prediction layer, and a label sequence optimization layer.The hybrid token embedding layer takes a token as an input and outputs its vector representation utilizing both the token embeddings and as well as the character embeddings.Let z 1: be the sequence of characters that com- prise a token x. Each character z i is first mapped to its embedding c i = V C (z i ), and the resulting sequence c 1: is input to a bidirectional LSTM, which outputs the character-based token embed- ding c.The output e of the hybrid token embedding layer for the token x is the concatenation of the character-based token embedding c and the token embedding t = V T (x).Let x 1:m be the sequence of tokens in a given sen- tence, and e 1:m be the corresponding embedding output from the hybrid token embedding layer. The sentence label prediction layer takes as in- put the sequence of vectors e 1:m , and outputs a, where the k th element of a, denoted a[k], reflects the probability that the given sentence has label k.To achieve this, the sequence e 1:m is first input to a bidirectional LSTM, which outputs the vector representation s of the given sentence. The vec- tor s is subsequently input to a feedforward neural network with one hidden layer, which outputs the corresponding probability vector a.PubMed 20k RCT We assembled this corpus consisting of randomized controlled trials (RCTs) from the PubMed database of biomedical litera- ture, which provides a standard set of 5 sentence labels: objectives, background, methods, results and conclusions. The label sequence optimization layer takes the se- quence of probability vectors a 1:n from the label prediction layer as input, and outputs a sequence of labels y 1:n , where y i is the label assigned to the token x i . In order to model dependencies between subse- quent labels, we incorporate a matrix T that con- tains the transition probabilities between two sub- sequent labels; we define T [i, j] as the probability that a token with label i is followed by a token with the label j. The score of a label sequence y 1:n is defined as the sum of the probabilities of individ- ual labels and the transition probabilities:The model is trained using stochastic gradient de- scent, updating all parameters, i.e., token embed- dings, character embeddings, parameters of bidi- rectional LSTMs, and transition probabilities, at each gradient step. For regularization, dropout with a rate of 0.5 is applied to the character- enhanced token embeddings and before the label prediction layer.  These scores can be turned into probabilities of the label sequences by taking a softmax function over all possible label sequences. During the training phase, the objective is to maximize the log prob- ability of the gold label sequence. In the testing phase, given an input sequence of tokens, the cor- responding sequence of predicted labels is chosen as the one that maximizes the score.We evaluate our model on the sentence classifica- tion task using the following two medical abstract datasets, where each sentence of the abstract is an- notated with one label. Table 1 presents statistics on each dataset.NICTA-PIBOSO This dataset was introduced in (Kim et al., 2011) and was the basis of the ALTA 2012 Shared Task ( Amini et al., 2012). Table 2 compares our model against several base- lines as well as the best performing model (Lui, 2012) in the ALTA 2012 Shared Task, in which 8 competing research teams participated to build the most accurate classifier for the NICTA- PIBOSO corpus.The first baseline (LR) is a classifier based on logistic regression using n-gram features extracted from the current sentence: it does not use any in- formation from the surrounding sentences. The second baseline (Forward ANN) uses the model presented in ( Lee and Dernoncourt, 2016): it com- putes sentence embeddings for each sentence, then classifies the current sentence given a few preced- ing sentence embeddings as well as the current sentence embedding. The third baseline (CRF) is a CRF that uses n-grams as features: each out- put variable of the CRF corresponds to a label for a sentence, and the sequence the CRF considers is the entire abstract. The CRF baseline there- fore uses both preceding and succeeding sentences when classifying the current sentence. Lastly, the model presented in (Lui, 2012    approach called feature stacking, which is a met- alearner that combines multiple feature sets, and is the best performing system on NICTA-PIBOSO published in the literature.The LR system performs honorably on PubMed 20k RCT (F1-score: 83.0), but quite poorly on NICTA-PIBOSO (F1-score: 71.6): this suggests that using the surrounding sentences may be more important in NICTA-PIBOSO than in PubMed 20k RCT. The Forward ANN system performs better than the LR system, and worse than the CRF: this is un- surprising, as the Forward ANN system only uses the information from the preceding sentences but does not use any information from the succeeding sentences, unlike the CRF.Our model performs better than the CRF sys- tem and the (Lui, 2012) system. We hypothesize that the following four factors give an edge to our model. No human-engineered features: Unlike most other systems, our model does not rely on any human-engineered features. No n-grams: While other systems heavily rely on n-grams, our model maps each token to a to- ken embedding, and feeds it as an input to an RNN. This helps combat data scarcity: for exam- ple, "chronic tendonitis" and "chronic tendinitis" are two different bigrams, but their token embed- dings should be very similar since they share the same meaning. Structured prediction: The labels for all sen- tences in an abstract are predicted jointly, which improves the coherence between the predicted la- bels in a given abstract. Joint learning: Our model learned the features and token embeddings jointly with the sequence optimization.  Figure 2 presents an example of a transition ma- trix after the model has been trained on PubMed 20k RCT. We can see that it effectively reflects transitions between different labels. For example, it learned that the first sentence of an abstract is most likely to be either discussing objective (0.23) or background (0.26). By the same token, a sen- tence pertaining to the methods is typically fol- lowed by a sentence pertaining to the methods (0.25) or the results (0.17). Table 3 details the result of our model for each label in PubMed 20k RCT: the main difficulty the classifier has is distinguishing background sen- tences from objective sentences.In this article we have presented an ANN architec- ture to classify sentences that appear in sequence. We demonstrate that jointly predicting the classes of all sentences in a given text improves the quality of the predictions and yields better performance than a CRF. Our model achieves state-of-the-art results on two datasets for sentence classification in medical abstracts.
