Assume that in August we train a pneumonia predictor. Our covariates consist of chest X-rays administered in the previous year (distribution P ) and the labels binary indicators of whether a physician diagnoses the patient with pneumonia. We train a convnet f to predict pneumonia given an X-ray image. Assume that in the training set .2% of patients have pneumonia. We deploy f in the clinic and for several months, it reliably predicts roughly .2% positive.Fast-forward to January (distribution Q): Running f on the last week's data, we find that 5% of patients are predicted to have pneumonia! Because f remains fixed, the shift must owe to a change in the marginal p(x), violating the familiar iid assumption. Absent familiar guarantees, we wonder: Is f still accurate? What's the real current rate of pneumonia? Shouldn't our classifier, trained under an obsolete prior, underestimate pneumonia when uncertain? Thus, we might suspect that the real prevalence is greater than 5%.4. Owing to generality, BBSE could be a standard diagnostic and corrective tool for arbitrary ML models.Despite its wide applicability, learning under label shift with unknown q(y) remains curiously under-explored. Noting the difficulty of the problem, Storkey [18] proposes placing a (meta-)prior over p(y) and inferring the posterior distribution from the test covariates. This requires explicitly estimating p(x|y), which may not be feasible in high-dimensional datasets. Chan &amp; Ng [4] infer q(y) using EM but their method also requires estimating p(x|y). Schölkopf et al. [16] articulates connections between label shift and anti-causal learning and Zhang et al. [22] extend the kernel mean matching approach due to [9] to the label shift problem. When q(y) is known, label shift simplifies to the problem of changing base rates [3,6].Covariate shift, also called sample selection bias, is well-studied [20,11,19,9]. Rosenbaum &amp; Rubin [15] introduce Propensity Scoring to design unbiased experiments. Shimodaira [17] is one of the earliest to propose correcting models via weighting examples in ERM by q(x)/p(x). Later works estimate importance weights from the available data, e.g., Gretton et al. [9] propose kernel mean matching to re-weight training points.The earliest relevant work to ours comes from econometrics and addresses the use of non-random samples to estimate behavior. Heckman [10] addresses sample selection bias, while [13] investigates estimating parameters under, choice-based or endogenous stratified sampling, cases analogous to a shift in the label distribution. Crucially, unlike our setting, they assume that the test set marginal distributions are both known. Also related to our work is the foundational research on propensity scoring [15] Finally, we note a connection to cognitive science work demonstrating that humans classify items differently depending on the set of unlabeled items in which they appear [23].Previous work requires estimating q(x), q(x)/p(x), or p(x|y), often relying on kernel methods, which scale poorly with dataset size and underperform on high-dimensional data. In contrast, BBSE uses black-box predictors to reduce dimensionality. It exploits advances in discriminative modeling and does not degrade, either in accuracy or tractability, as data or feature dimensions grow.We use x ∈ X = R d and y ∈ Y to denote the feature and label variables. For simplicity, we assume that Y is a discrete domain equivalent to {1, 2, ..., k}. Let P, Q be the source and target distributions defined on X × Y. We use p, q to denote the probability density function (pdf) or probability mass function (pmf) associated with P and Q respectively. The random variable of interest is clear from context. For example, p(y) is the p.m.f. of y ∼ P and q(x) is the p.d.f. of x ∼ Q. Moreover, p(y = i) and q(y = i) are short for P P (y = i) and P Q (y = i) respectively, where P(S) := E[1(S)] denotes the probability of an event S and E[·] denotes the expectation. Subscripts P and Q on these operators make the referenced distribution clear.In standard supervised learning, the learner observes training data (x 1 , y 1 ), (x 2 , y 2 ), ..., (x n , y n ) drawn iid from a training (or source) distribution P . We denote the collection of feature vectors by X ∈ R n×d and the label by y. Under Domain Adaptation (DA), the learner additionally observes a collection of samples X = [x 1 ; ...; x m ] drawn iid from a test (or target) distribution Q. Our objective in DA is to predict well for samples drawn from Q.In general this task is impossible, e.g., P and Q might not share support. This paper considers DA under 3 extra assumptions:A.1 The label shift (also known as target shift) assumptionA.2 For every y ∈ Y with q(y) &gt; 0 we require p(y) &gt; 0. We now comment on the assumptions. A.1 corresponds to anti-causal learning. This assumption is strong but reasonable in many practical situations, including medical diagnosis, where diseases cause symptoms. It also applies when classifiers are trained on non-representative class distributions: Note that while visions systems are commonly trained with balanced classes [5], the true class distribution for real tasks is rarely uniform.Assumption A.2 addresses identifiability, requiring that the target label distribution's support be a subset of training distribution's. For discrete Y, this simply means that the training data should contain examples from every class.Assumption A.3 requires that the expected predictor outputs for each class be linearly independent. This assumption holds in the typical case where the classifier predicts class y i more often given images actually belong to y i than given images from any other class y j . In practice, f could be a neural network, a boosted decision-tree or any other classifier trained on a holdout training data set. We can verify at training time that the empirical estimated normalized confusion matrix is invertible. Assumption A.3 generalizes naturally to soft-classifiers, where f outputs a probability distribution supported on Y. Thus BBSE can be applied even when the confusion matrix is degenerate.Objective We wish to estimate w(y) := q(y)/p(y) for every y ∈ Y with training data, unlabeled test data and a predictor f . This estimate enables DA techniques under the importance-weighted ERM framework, which solves minUnder the label shift assumption, the importance weight w i = q(y i )/p(y i ). This task isn't straightforward because we don't observe samples from q(y).We now derive the main results for estimating w(y) and q(y). Assumption A.1 has the following implication: Lemma 1. Denote byˆybyˆ byˆy = f (x) the output of a fixed function f : X → Y. If Assumption A.1 holds, then q(ˆ y|y) = p(ˆ y|y).The proof is simple: recall thatˆythatˆ thatˆy depends on y only via x. By A.1, p(x|y) = q(x|y) and thus q(ˆ y|y) = p(ˆ y|y).Next, combine the law of total probability and Lemma 1 and we arrive aty∈Y y∈YWe estimate p(ˆ y|y) and p(ˆ y, y) using f and data from source distribution P , and q(ˆ y) with unlabeled test data drawn from target distribution Q. This leads to a novel method-of-moments approach for consistent estimation of the shifted label distribution q(y) and the weights w(y).Without loss of generality, we assume Y = {1, 2, ..., k}. Denote bymoments of p and q and their plug-in estimates, defined viaWe can now rewrite Equation (1) in matrix form:Using plug-in maximum likelihood estimates of the above quantities yields the estimatorsˆwwherê ν y is the plug-in estimator of ν y .Next, we establish that the estimators are consistent. The proof (see Appendix A) uses the First Borel-Cantelli Lemma to show that the probability that the entire sequence of empirical confusion matrices with data size n + 1, ..., ∞ are simultaneously invertible converges to 1, thereby enabling us to use the continuous mapping theorem after applying the strong law of large numbers to each component.We now address our estimators' convergence rates. Theorem 3 (Error bounds). Assume that A.3 holds robustly. Let σ min be the smallest eigenvalue of C ˆ y,y . There exists a constant C &gt; 0 such that for all n &gt; 80 log(n)σ −2 min , with probability at leastThe bounds give practical insights (explored more in Section 7). In (2), the square error depends on the sample size and is proportional to 1/n (or 1/m). There is also a 2 term that reflects how different the source and target distributions are. In addition, σ min reflects the quality of the given classifier f . For example, if f is a perfect classifier, then σ min = min y∈Y p(y). If f cannot distinguish between certain classes at all, then C ˆ y,y will be low-rank, σ min = 0, and the technique is invalid, as expected.We now parse the error bound ofˆµofˆ ofˆµ y in (3). The first term 2 /n is required even if we observe the importance weight w exactly. The second term captures the additional error due to the fact that we estimate w with predictor f . Note that y 2 ∞ ≤ 1 and can be as small as 1/k 2 when p(y) is uniform. Note that when f correctly classifies each class with the same probability, e.g. 0.5, then y 2 /σ 2 min is a constant and the bound cannot be improved.Proof of Theorem 3. Assumption A.2 ensures that w &lt; ∞.By completing the square and Cauchy-Schwartz inequality,By the Woodbury matrix identity, we get thatˆC thatˆ thatˆCy,y . Substitute into the above inequality and use (1) to getˆwWe now provide a high probability bound on the Euclidean norm of E 2 , the operator norm of E 1 , which will give us an operator norm bound of [E −1−1 under our assumption on n, and these will yield a high probability bound on the square estimation error.Operator norm of E 1 . Note thatˆCˆythatˆ thatˆCthatˆCˆ thatˆCˆy,y = 1 n n i=1 e f (xi) e T yi , where e y is the standard basis with 1 at the index of y ∈ Y and 0 elsewhere. Clearly,Take t = √ 20n log n and use the assumption that n ≥ 4 log n/9 (which holds under our assumption on n since σ min &lt; 1). Then with probability at least 1 − 2kn −10 1 ≤ 20 log n n .Using the assumption on n, we have 1 ≤ σ min /2Also, we havê. By the standard Hoeffding's inequality and union bound argument, we have that with probability larger than 1 − 2kmSubstitute into Equation (4), we getˆwwhich holds with probability 1 − 2kn −10 − 2km −10 . We now turn tô µ y . Recall thatˆµthatˆ thatˆµ y = diag(ˆ ν y ) ˆ w. Let the estimation error ofˆνofˆ ofˆν y be E 0 .By Hoeffding's inequlaity 0 ∞ ≤ 20 log n n with probability larger than 1 − kn −10 . Combining with (5) yieldsˆµ Figure 1: Label-shift detection on MNIST. Pane 1a illustrates that Type I error is correctly controlled absent label shift. Pane 1b illustrates high power under mild label-shift. Pane 1c shows increased power for better classifiers. We compare to kernel two-sample tests [21] and an (infeasible) oracle two sample test that directly tests p(y) = q(y) with samples from each. The proposed test beats directly testing in high-dimensions and nearly matches the oracle.Formally, detection can be cast as a hypothesis testing problem where the null hypothesis is H 0 : q(y) = p(y) and the alternative hypothesis is that H 1 : q(y) = p(y). Recall that we observe neither q(y) nor any samples from it. However, we do observe unlabeled data from the target distribution and our predictor f . Proposition 4 (Detecting label-shift). Under Assumption A.1, A.2 and for each classifier f satisfying A.3 we have that q(y) = p(y) if and only if p(ˆ y) = q(ˆ y).Proof. Plug P and Q into (1) and apply Lemma 1 with assumption A.1. The result follows directly from our analysis in the proof of Proposition 2 that shows p(ˆ y, y) is invertible under the assumptions A.2 and A.3.Thus, under weak assumptions, we can test H 0 by running two-sample tests on readily available samples from p(ˆ y) and q(ˆ y). Examples include the Kolmogorov-Smirnoff test, Anderson-Darling or the Maximum Mean Discrepancy. In all tests, asymptotic distributions are known and we can almost perfectly control the Type I error. The power of the test (1-Type II error) depends on the classifier's performance on distribution P , thereby allowing us to leverage recent progress in deep learning to attack the classic problem of detecting non-stationarity in the data distribution.One could also test whether p(x) = q(x). Under the label-shift assumption this is implied by q(y) = p(y). The advantage of testing the distribution of f (x) instead of x is that we only need to deal with a one-dimensional distribution. Per theory and experiments in [14] two-sample tests in high dimensions are exponentially harder.   One surprising byproduct is that we can sometimes use this approach to detect covariate-shift, concept-shift, and more general forms of nonstationarity. Proposition 5 (Detecting general nonstationarity). For any fixed measurable f :This follows directly from the measurability of f .While the converse is not true in general, p(ˆ y) = q(ˆ y) does imply that for every measurableThis suggests that testingˆHtestingˆ testingˆH 0 : p(ˆ y) = q(ˆ y) may help us to determine if there's sufficient statistical evidence that domain adaptation techniques are required.   Our estimator also points to a systematic method of correcting for label-shift via importance-weighted ERM. Specifically, we propose the following algorithm:input Samples from source distribution X, y. Unlabeled data from target distribution X . A class of classifiers F. Hyperparameter 0 &lt; δ &lt; 1/k. 1. Randomly split the training data into two X 1 , X 2 ∈ R n/2×d and y 1 , y 2 R n/2 . 2. Use X 1 , y 1 to train the classifier and obtain f ∈ F. 3. On the hold-out data set X 2 , y 2 , calculate the confusion matrixˆCˆymatrixˆ matrixˆCmatrixˆCˆ matrixˆCˆy,y . If , if σ minˆCˆy minˆ minˆCminˆCˆ minˆCˆy,y ≤ δ thenSolve the importance weighted ERM on the X 1 , y 1 with max( ˆ w, 0) and obtaiñ f . output˜foutput˜ output˜fNote that for classes that occur rarely in the test set, BBSE may produce negative importance weights. During ERM, a flipped sign would cause us to maximize loss, which is unbounded above. Thus, we clip negative weights to 0.Owing to its efficacy and generality, our approach can serve as a default tool to deal with domain adaptation. It is one of the first things to try even when the label-shift assumption doesn't hold. By contrast, the heuristic method of using logistic-regression to construct importance weights [2] lacks theoretical justification that the estimated weights are correct.Even in the simpler problem of average treatment effect (ATE) estimation, it's known that using estimated propensity can lead to estimators with large variance [12]. The same issue applies in supervised learning. We may prefer to live with the biased solution from the unweighted ERM rather than suffer high variance from an unbiased weighted ERM. Our proposed approach offers a consistent low-variance estimator under label shift.We experimentally demonstrate the power of BBSE with real data and simulated label shift. We organize results into three categories -shift detection with BBSD, weight estimation with BBSE, and classifier correction with BBSC. BBSE-hard denotes our method where f yields classifications. In BBSE-soft, f outputs probabilities.Label Shift Simulation To simulate distribution shift in our experiments, we adopt the following protocols: First, we split the original data into train, validation, and test sets. Then, given distributions p(y) and q(y), we generate each set by sampling with replacement from the appropriate split. In knock-out shift, we knock out a fraction δ of data points from a given class from training and validation sets. In tweak-one shift, we assign a probability ρ to one of the classes, the rest of the mass is spread evenly among the other classes. In Dirichlet shift, we draw p(y) from a Dirichlet distribution with concentration parameter α. With uniform p(y), Dirichlet shift is bigger for smaller α.Label-shift detection We conduct nonparametric two-sample tests as described in Section 5.1 using the MNIST handwritten digits data set. To simulate the label-shift, we randomly split the training data into a training set, a validating set and a test set, each with 20,000 data points, and apply knock-out shift on class y = 53 . Note that p(y) and q(y) differ increasingly as δ grows large, making shift detection easier. We obtain f by training a two-layer ReLU-activated Multilayer Perceptron (MLP) with 256 neurons on the training set for five epochs. We conduct a two-sample test of whether the distribution of f (Validation Set) and f (Test Set) are the same using the Kolmogorov-Smirnov test. The results, summarized in Figure 1, demonstrate that BBSD (1) produces a p-value that distributes uniformly when δ = 0 4 (2) provides more power (less Type II error) than the state-of-the-art kernel two-sample test that discriminates p(x) and q(x) at δ = 0.5, and (3) gets better as we train the black-box predictor even more.Weight estimation and label-shift correction We evaluate BBSE on MNIST by simulating label shift and datasets of various sizes. Specifically, we split the training data set randomly in two, using first half to train f and the second half to estimate w. We use then use the full training set for weighted ERM. As before, f is a two-layer MLP. For fair comparisons with baselines, the full training data set is used throughout (since they do not need f without data splitting). We evaluate our estimatorˆwestimatorˆ estimatorˆw against the ground truth w and by the prediction accuracy of BBSC on the test set. To cover a variety of different types of label-shift, we take p(y) as a uniform distribution and generate q(y) with Dirichlet shift for α = 0.1, 1.0, 10.0 ( Figure 2).Label-shift correction for CIFAR10 Next, we extend our experiments to the CIFAR dataset, using the same MLP and this time allowing it to train for 10 epochs. We consider both tweak-one and Dirichlet shift, and compare BBSE to the unweighted classifier under varying degrees of shift ( Figure 4). For the tweak-one experiment, we try ρ ∈ {0.0, 0.1, ..., 1.0}, averaging results over all 10 choices of the tweaked label, and plotting the variance. For the Dirichlet experiments, we sample 20 q(y) for every choice of α in the range {1000, 100, ..., .001}. Because the kernel-based baselines cannot handle datasets of this size and dimensionality, here we compare only to unweighted ERM.Kernel mean matching (KMM) baselines We compare BBSE to the state-of-the-art kernel mean matching (KMM) methods. For the detection experiments (Figure 1), our baseline is the kernel B-test [21], an extension of the kernel max mean discrepancy (MMD) test due to Gretton et al. [8] that boasts nearly linear-time computation and little loss in power. We compare BBSE to a KMM approach Zhang et al. [22], that solveswhere we use operator C x|y := E[φ(x)|ψ(y)] and function µ x := E Q [φ(x)] to denote the kernel embedding of p(x|y) and p Q (x) respectively. Note that under the label-shift assumption, C x|y is the same for P and Q. Also note that since Y is discrete, ψ(y) is simply the one-hot representation of y, so ν y is the same as our definition before and C x|y , ν y and µ x must be estimated from finite data. The proposal involves a constrained optimization by solving a Gaussian process regression with automatic hyperparameter choices through marginal likelihood.For fair comparison, we used the original authors' implementations as baselines 5 and also used the median trick to adaptively tune the RBF kernel's hyperparameter. A key difference is that BBSE matches the distribution ofˆyofˆ ofˆy rather than distribution of x like [22] and we learn f through supervised learning rather than by specifying a feature map φ by choosing a kernel up front.Note that KMM, like many kernel methods, requires the construction and inversion of an n × n Gram matrix, which has complexity of O(n 3 ). This hinders its application to real-life machine learning problems where n will often be 100s of thousands. In our experiments, we find that the largest n for which we can feasibly run the KMM code is roughly 8, 000 and that is where we unfortunately have to stop for the MNIST experiment. For the same reason, we cannot run KMM for the CIFAR10 experiments. The MSE curves in Figure 2 for estimating w suggest that the convergence rate of KMM is slower than BBSE by a polynomial factor and that BBSE better handles large datasets.Constructing the training Set The error bounds on our estimates depend on the norm of the true vector w(y) := q(y)/p(y). This confirms the common sense that absent any assumption on q(y), and given the ability to select class-conditioned examples for annotations one should build a dataset with uniform p(y). Then it's always possible to apply BBSE successfully at test time to correct f .Sporadic Shift In some settings, p(y) might change only sporadically. In these cases, when no label shift occurs, applying BBSC might damage the classifier. For these cases, we prose to combine detection and estimation, correcting the classifier only when a shift has likely occurred.Using known predictor In our experiments, f has been trained using a random split of the data set, which makes BBSEto perform worse than baseline when the data set is extremely small. In practice, especially in the context of web services, there could be a natural predictor f that is currently being deployed whose training data were legacy and have little to do with the two distributions that we are trying to distinguish. In this case, we do not lose that factor of 2 and we do not suffer from the variance in training f with a small amount of data. This could allow us to detect mild shift in distributions in very short period of time. Making it suitable for applications such as financial market prediction.BBSE with degenerate confusion matrices In practice, sometime confusion matrices will be degenerate. For instance, when a class i is rare under P , and the features are only partially predictive, we might find that p(f (x) = i) = 0. In these cases, two straightforward variations on the black box method may still work: First, while our analysis focuses on confusion matrices, it easily extends to any operator f , such as soft probabilities. If each class i, even if i is never the argmax for any example, so long as p(ˆ y = i|y = i) &gt; p(ˆ y = i|y = j) for any j = i, the soft confusion matrix will be invertible. Even when we produce and operator with an invertible confusion matrix, two options remain: We can merge c classes together, yielding a (k − c) × (k − c) invertible confusion matrix. While we might not be able to estimate the frequencies of those c classes, we can estimate the others accurately. Another possibility is to compute the pseudo-inverse.Future Work As a next step, we plan to extend our methodology to the streaming setting. In practice, label distributions tend to shift progressively, presenting a new challenge: if we apply BBSE on trailing windows, then we face a trade-off. Looking far back increases m, lowering estimation error, but the estimate will be less fresh. The use of propensity weights w on y makes BBSE amenable to doubly-robust estimates, the typical bias-variance tradeoff, and related techniques, common in covariate shift correction.We present the proofs of Lemma 1 and Proposition 2 in this Appendix. We applied A.1 to the second equality, and used the conditional independencê y ⊥ ⊥ y|x under P and Q together with p(ˆ y|x) being determined by f , which is fixed.Proof of Proposition 2. A.2 ensures that w &lt; ∞. By Assumption A.3, C ˆ y,y is invertible. Let δ &gt; 0 be its smallest singular value. We bound the probability thatˆCˆythatˆ thatˆCthatˆCˆ thatˆCˆy,y is not invertible: Then for all t ≥ 0,
