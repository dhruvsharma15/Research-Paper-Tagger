As the performance of machine learning algorithms has skyrock- eted over recent years the often unspoken relationship between the human data scientist and the machines they run has evolved significantly. A great deal of work has been put into new state- of-the-art methods, and researchers are constantly optimising the various aspects of machine learning algorithms. Such efforts include proposing algorithms for optimising hyperparameters and network architectures [1] and the latest trends show increasing emphasis on algorithms that require less human intervention. Consider the automatic statistician project 1 which aims at removing the data 1 https://www.automaticstatistician.com/index/ scientist from the process of understanding data by using Bayesian model selection. Real et al. [1] propose an evolutionary algorithm for optimising image classification neural networks which requires no human intervention in creating the networks. Similarly, Zoph and Le [2] use recurrent neural networks along with reinforcement learning in order to achieve a similar goal. It is clear from these research efforts that this is a trend that will continue, driven both by potential industrial profits to compensate for shortages of ex- pensive data scientists and by the general goal of Artificial General Intelligence (AGI).Nevertheless, for most current machine learning algorithms, there is a considerable amount of human intervention which must be performed prior to the final execution of the algorithm. For ex- ample, setting the number of parameters, preprocessing the data, deciding on the loss function and interpreting the results, to name a few. Another example, and perhaps the first of the steps in the data science process, is problem identification: "does a supervised set of data correspond to a classification or regression problem?" Under- standing which type of the two problems a given dataset represents is a step in the direction of automated machine learning research and is the subject of this study.Classification problems typically represent a set of problems whereby the goal is to create a predictive model that can discrim- inate between various known classes. CIFAR-10 and MNIST are examples of classification datasets where the goals are to identify the correct label (airplane, automobile, bird, cat etc... and digits re- spectively) for each image. For regression problems, the predictive output is continuous (as opposed to discrete in the case of classifi- cation). An example of a regression dataset is the Boston housing price regression dataset for which the goal is to predict the median value of the houses.In the context of deep learning [3], when presented with a dataset, typically one will verify whether the data represents a classification or a regression problem, and then will decide on the loss function and network layers accordingly. For the CIFAR-10 image dataset, one might consider using convolutional, dropout and fully con- nected layers; and for the Boston housing price dataset one might use fully connected and dropout layers. Furthermore, a decision should be made with regards to which loss function (or equivalently, figure of merit) to use. For CIFAR-10 one might use categorical cross entropy, and use the mean squared error loss function for the Boston housing case. As researchers in machine learning, in most cases, these decisions can be made with relative ease. For a machine, on the other hand, this decision is non-trivial and current machine learning algorithms do not automatically decide if a given dataset an example of a network architecture generated by an API chromosome (which was obtained at the end of an execution of the API algorithm). The input dataset was CIFAR-10 -an image classification dataset. The chromosome recommended that the last layer should have 10 units and that these should use the sigmoid activation function. Furthermore, the chromosome recommended using the categorical cross entropy loss function, and consequently, correctly determined that the dataset was a classification problem.is a classification or a regression problem; nor do they recommend a loss function.In this study, a genetic algorithm (GA) harnessed to a dynamic and flexible deep learning framework is proposed for the automated identification of problems. We call this the Automated Problem Identification (API) algorithm and show that it can successfully determine if a dataset is a classification or a regression one; and furthermore, recommend whether to use categorical cross entropy or mean-squared error. Additionally, API will recommend which layers (e.g. convolutional or fully connected) -from a known set -to use, either as the final architecture or as the input to further optimisation. Figure 1 illustrates an example of a network which was produced by a chromosome when the CIFAR-10 dataset was input into API. The resulting architecture is very similar to one that a human might use for the problem. This paper is organized as follows: Section 2 describes GAs. Section 3 describes the API chromosome which is used to determine if a dataset is a classification or a regression optimisation problem. Section 4 provides the details for the proposed API algorithm. The experimental setup is presented in Section 5 and Section 6 discusses the results. We conclude in Section 7 and discus our future work.input : generation_max: maximum number of GA generations 1 begin 2Create an initial population of chromosomes.Evaluate the initial population.   Select the parents.Perform the genetic operators.Replace the current population with the new offspring created in step 8.Evaluate the current population.return The best chromosome.A Genetic Algorithm (GA) [4] is a biologically inspired evolutionary algorithm [5]. GAs mimic the way that species fight for survival and reproduce in nature. A GA makes use of a population of chromo- somes to solve an optimisation problem. Each chromosome encodes a potential solution to the problem. Over time the chromosomes undergo many modifications, known as genetic operators, in order to traverse the search space. A fitness function is used to determines how good a chromosome is at solving the optimisation problem. Each generation parent chromosomes are selected and genetic op- erators are applied to those parents to create offspring which then constitute the new chromosome -and parent -population. The new population is evaluated for fitness and the process is repeated; as illustrated in Algorithm 1.In this section and the following subsections, we describe the API chromosome along with a description about each of the genes within the chromosome. In this study, the word layer refers to the layers in deep neural network architectures. Each chromosome is made up of four genes, namely, the neural network loss function, the number of units in the last layer of the neural network, the activation function used in the last layer and the configuration of the layers (configurations are explained in section 3.4). A chromosome thus encodes an entire deep neural network architecture and an associated loss function. Figure 2 illustrates an example of an API chromosome that en- codes a neural network architecture with the following layers: fully connected, dropout and two fully connected layers. Furthermore, the chromosome will apply the mean squared error loss function (during the training of the neural network) and the last layer has 1 unit of which the activation function is a rectified linear unit.The following subsections provide additional details about the four genes.We chose to use GAs since the number of genes can easily be modified in order to encode additional complexity and to easily handle the discrete nature of the parameters being chosen, since API searches through a space of network architectures in addition to other parameters. We can increase the complexity of the chro- mosomes by including more parameters, as we discuss in section 7.then for sample i, CCE = − ln(0.1). Network N 2 is preferred since − ln(0.1) &gt; − ln(0.7).The second gene denotes the number of units in the last layer in the network. There are two possible values for this gene: one or U , where U denotes the number of unique values in Y (Y repre- sents the target values for a dataset). Formally, U = |S |, where S = {y i } i ∈ {1, ..., N } and N is the number of samples. For example, assume that for some dataset Y = (0, 1, 0, 2, 3, 2, 3, 0, 2, 3, 1, 1) then U = 4 since there are 4 unique values in the targets. This gene takes on four possible values and denotes which acti- vation function will be used in the last layer in the network. The possible values are: {linear, relu, sigmoid, softmax}. Here 'relu' refers to rectified linear units. Given some input x to a layer, the equations for each of the activation functions are presented in equations 3 to 6 respectively.This gene represents the loss function that will be used when train- ing the network and it takes on two possible values: Mean Squared Error (MSE) and Categorical Cross Entropy (CCE) loss. Let y i de- note the target label for sample i, ¯ y i denote the model's predicted output for sample i and N denote the number of training samples. The mean-squared error used in this study is presented in equation 1.For example, let y = [2.2 5.5 0.2] and assume that some network61. Network N 1 is preferred since 0.09 &lt; 7.61. When using the MSE, the objective of an optimisation algorithm will be to minimise the MSE value to reduce the distance between the correct values and the model's predicted values.The categorical cross entropy used in this study is presented in equation 2.When using this loss function the objective is to maximise the CCE in such a way to make the network predictions are as simi- lar to the labels as possible. In this case, the target labels will be represented as a vector (often one-hot encoded vectors) and the network predictions will also be in a vector of the same length. Each chromosome has a gene which corresponds to the architecture of the network which we define as the configuration. The config- uration represents the exact sequence of the network layers and is stored in a list. The first element in the configuration represents the first layer and the last element represents the last layer. There are four possible values which each element in the configuration can take, namely: convolution [6], fully connected, dropout [7] and max pooling [8]. Here, convolution refers to two-dimensional convolution. We add dropout to the list of possible configuration values even though dropout is not a layer. The size of the configurations is randomly selected between 5 and 15. The configurations are initialised randomly during the initial population generation and modified during the mutation operator; these are explained in sections 4.1 and 4.3.1 respectively. Each of the layers are mapped to an integer value, i.e. convolution is mapped to 0, fully connected to 1, dropout to 2 and max pooling to 3. Each chromosome has exactly one configuration.We provide the following example to illustrate the configurations. Let the configuration for a chromosome be: [2, 0, 3, 3, 0, 0, 1, 2, 1, 1]; figure 1 illustrates this network. The network is comprised Emmanuel Dufourq and Bruce A. Bassett of several convolution and max pooling layers followed by fully connected and dropout layers.GAs make use of a fitness function to evaluate how good a chro- mosome is at solving an optimisation problem. In our case, we designed a fitness function to discriminate between classification and regression problems. When the proposed system commences, it splits the dataset into two subsets, the features, X and the labels Y . The labels are then converted into their corresponding one-hot encoded values. The validation loss is recorded during the optimisation of the neu- ral network across the epochs. Let the validation loss be V 0 , V 1 , ..., V e where e denotes the total number of epochs and V i denote the vali- dation loss for epoch i. We define the change in validation as follows,Finally, we define the ratio in validation drop, R, as R = Figure 3: During the training of each neural network on the validation data we record the validation loss. We then deter- mine whether or not the network has learnt. If the network has not learnt (R ≥ 0) then we penalise the chromosome with a very large fitness. However, if the network was able to learn (R &lt; 0) then we assign the mean squared error as the fitness value.. Thus, for each chromosome, after the optimisation of the neural network has taken place, we compute R, and if R &gt; 0 then this implies that the network has not done any learning since the validation loss increased. Furthermore, if R = 0 then once again the network has not managed to learn anything since the validation loss has remained constant over the epochs. Finally, if R &lt; 0 we conclude that given the drop in validation loss, that the network has managed to learn.The model then predicts the output values on the validation data. The predictions and the validation target values are compared using mean squared error. The loss obtained on the validation data using categorical cross entropy will be different to the loss computed using mean squared error. We chose to use the mean squared error to be consistent with the comparisons. In the case whereby the network has not learnt anything we penalise the chromosome with a fitness of infinity. However, in the case whereby the network has learnt, i.e. R &lt; 0, then we assign the computed validation mean squared error as the fitness of the chromosome. The objective of the API algorithm is thus to minimise the fitness of each chromosome by rewarding networks that learn and have a small mean squared error on the validation set. The lower the fitness value the better a chromosome performed. Figure 3 illustrates a plot which explains the fitness of a chromo- some. The plot is separated in two where R = 0. From the plot, it is observed that when R ≥ 0 then the fitness is set to a very large value. When R &lt; 0 then the value of the fitness corresponds to the mean squared error whereby a smaller value is better. For the sake of the example, a straight line was drawn for R &lt; 0 to illustrate that a smaller mean squared error results in a better chromosome fitness.Since the chromosomes are randomly generated, it is possible that they represent invalid networks for particular features and labels on a given dataset. For example, assume that, for some chro- mosome, the number of units in the last layer is 1 and the categorical cross entropy loss function is used. Given the previous description in this subsection, the one-hot encoded Y values should be used during training. However, in the example, the number of outputs is 1 and thus a one-hot encoded vector cannot be compared to a single value. To illustrate with another example, consider a chromosome that tries to use convolutional layers on a feature based regression dataset -this is, of course, not feasible. Invalid chromosomes such as this are penalised with a fitness of infinity. Section 4.4 describes how the chromosome makes the discrimination between regression and classification.The following subsections explain how each aspect of the GA has been adapted to determine if a given dataset is a classification or regression problem. Furthermore, the algorithm recommends the following upon termination: the loss function which should be used in order to enable the training of a neural network, the number of units and type of activation function in the last layer and finally, a simple network architecture is also recommended. The API algo- rithm performs optimisation in two phases, namely in optimising the GA population, and since each chromosome represents a neural network, optimisation is performed when training the networks.The initial population size is set to the same value as the user- defined population size. Suppose the population size is n, then n chromosomes are created during the initial population generation. Each chromosome has a fixed length of 4 genes (discussed in section 3). During the creation of a chromosome, each gene is randomly created based on the values each gene can take on. The pseudocode for creating a chromosome is presented in algorithm 2. The initial fitness of each chromosome is set to infinity.Algorithm 2: Creating a chromosome.Initialise an empty chromosome.Set the loss function to either categorical cross entropy or mean squared error.Set the number of units in the last layer to either one or U .Set the activation function in the last layer to either linear, sigmoid, softmax or relu.gene is randomly selected and a new value for that gene is created. A user-defined parameter is associated with the mutation operator, namely the mutation application rate. Figure 4 illustrates the ap- plication of the mutation operator on a parent chromosome, and the resulting offspring is illustrated. From the example, the forth gene was selected for mutation and thus the forth gene within the parent was changed from a configuration of [1, 2, 1, 1] to [1, 1, 1, 1, 1] in the offspring.Create a random configuration.Parent selection methods are used to obtain parents from the current population of chromosomes. These parents are used by the genetic operators to create offspring. A single parent is obtained when the parent selection method is executed. Once a chromosome has been chosen to be a parent, the selection method can select that particular chromosome again. Three common parent selection methods are fitness-proportionate, rank and tournament selection [9]. For this study, tournament selection was used given that it was shown to be a successful method by Zhong et al. [10]. Algorithm 3 presents the pseudocode for the tournament selec- tion. This selection method has one user-defined parameter, namely, the tournament size. Let k be the tournament size. Tournament selection randomly selects k chromosomes from the current GA population, and compares the fitness of each of the k chromosomes. The chromosome with the lowest fitness is returned as the parent chromosome. If a tie occurs, then a random chromosome is selected to break the tie.  The crossover genetic operator exchanges ge- netic material between two parent chromosomes: parent 1 and parent 2 , and consequently creates two offspring: offspring 1 and offspring 2 . There are several variations of the crossover genetic operator, such as uniform, one-point and two-point crossover.The crossover method we implement randomly selects a position p in the range [0, n] -where n denotes the length of the chromo- some -within the parent chromosomes; the same position p must be selected within the two parents. Two offspring are created, and all the genes except those at position p are copied across to the cor- responding offspring without modification. The genes are position p are swapped, i.e., the gene in position p from parent 1 is inserted into position p in offspring 2 , and similarly, the gene in position p from parent 2 is inserted into position p in offspring 1 .An example of the application of the crossover operator is pre- sented in figure 5. The figure shows two parent chromosomes. The crossover point was the third gene from each parent, i.e. the last ac- tivation function was swapped between the parents. The offspring show the result of the crossover.Genetic operators are applied to parents to exchange genetic mate- rial between the parent chromosomes, and to consequently create novel offspring. The two most common genetic operators are mu- tation and crossover. Their implementation details for this study are described below. At the end of the generational loop, the best chromosome is output. The loss function in the best chromosome is then used to decide if the dataset was a classification or a regression problem. If the loss function was categorical cross entropy, then the problem was labelled as classification. However, if the loss function was mean squared error then the problem was labelled as regression. Figure 5: Example of the crossover operator being applied two parent chromosomes. The third gene from both of the parents were selected for crossover. As a result, the last acti- vation functions were swapped between the parents.This section describes the experimental set up which was used to evaluate the performance of API. The algorithm was programmed in Python 3.6.0 and TensorFlow 1.1.0 [11]. The algorithm was eval- uated on a machine with an Intel Core i7-6700K CPU and 16GB RAM. Table 1 presents the 16 datasets which were used in this study along with their characteristics and type. All of the datasets were obtained from the UCI machine learning repository [12] except for CIFAR-10 and CIFAR-100 which were obtained from [13], MNIST from [14], CrowdFlower 2 , Aloi 3 and IMDB 4 were obtained exter- nally. In this study, CrowdFlower represents the 'emotion in text' dataset. The assumptions are that there are no missing values in each dataset and that categorical features are converted to corre- sponding numerical features using a one-hot encoding approach. Of course, it would be possible to implement an imputation method [15] to overcome datasets with missing values, however, this was not part of the scope of this study. The algorithm standardises each feature. Where possible, we used 1000 samples for training and 1000 for validation. Boston housing, for example, did not have that many samples. In this case, we simply split the dataset equally into two sets. We distinguish between data and image classification problems because in the former the data are typically resented by one-dimensional vectors; whereas, image classification datasets are commonly represented as three-dimensional arrays. API can adapt to the various input shapes without human intervention.Features  Table 1: The 16 datasets used in this study. We used datasets from four problem domains with various characteristics and are denoted as follows: 'D' represents data classification, 'R' for regression, 'IC' for image classification and 'SA' for sen- timent analysis. The sentiment analysis datasets were con- sidered as classification problems. The unique targets refers to the unique number of outputs in the target values for each dataset. For example, for CIFAR-10 has 10 unique tar- get classes, whereas Relative CT Slice has 15903 unique tar- get values. For CrowdFlower and IMDB we used a bags of words approach in order to generate word embeddings.Value Crossover rate 70% Mutation rate 30% Number of generations 10 Tournament size 5 Population size 50 Table 2: The GA parameters used in this study. Preliminary experiments revealed that we did not need to use a large pop- ulation size or a large number of generations to evolve accu- rate solutions.The GA and neural network parameters used in this study are presented in tables 2 and 3 respectively. These parameters were obtained by preliminary runs of the algorithm. The purpose of this study was to evolve chromosomes that could determine whether a given dataset was classification or regression in addition to several other outputs. Certain variables had to remain fixed in order to evolve the chromosomes. Each parameter in table 3 was set to a fixed value. The results obtained by API are presented and discussed in this section. The Aloi dataset was included in the experiments because one could hypothesise that if a dataset has a large number of targets then it is a regression dataset. For this reason, we included Aloi as it has a much larger number of classes in comparison to the other classification datasets. The accuracy results achieved by API on the 16 datasets across the 20 runs are presented in figure 6. When discriminating between regression or classification problems, API obtained an average accuracy of 96.3%, the lowest accuracy was 90% which was obtained on 3 datasets and the highest accuracy was 100% which was achieved on 7 datasets.  Table 3: The neural network parameters used in this study. When training a neural network contained in a chromo- some each of the parameters listed in this table were applied. Table 4 presents the number of times, out of 20 runs, that API incorrectly classified each dataset. There were 3 datasets for which API incorrectly classified two runs, this represents an accuracy of 90%. There was no dataset for which the performance across the runs was less than 90%.In the case of the two misclassifications for the CIFAR-10 dataset, the fitness for chromosomes having the mean squared error and the categorical cross entropy loss function were very close. It happened to be that, for that particular run, the former had a slightly lower fitness. In the second case, the population was rapidly dominated by chromosomes having the mean squared error loss function as the generational loop progressed. A similar observation was made for the other incorrectly classified runs. Two possible ways of over- coming this issue would be to re-introduce genetic diversity into the population by randomly initialising a number of chromosomes across the generations. This would thus allow chromosomes con- taining both types of loss functions to be present in the popula- tion. Alternatively, increasing the tournament size could allow for weaker chromosomes to remain in the population which could in turn preserve the balance between the chromosomes containing both loss functions.Appendix A presents, for each dataset, an example chromosome that was evolved. These chromosomes were randomly selected from each of the 20 runs. The networks varied in size from 5 to 15 layers, however, in most cases the networks were deep. The architecture generated for the image classification problems are more complex than the ones generated for the other problems. In particular, the evolved chromosome for the CIFAR-10 dataset was of interest because the configuration resembles an architecture that a human might generated when creating a deep neural network for image classification. For instance, consider AlexNet [13], which is made up of a series of convolutional and max pooling layers towards the start of the network, and ends with three fully connected layers. In a similar way, the chromosome's architecture which is presented in the appendix has a similar structure of convolutions and max pooling layers followed by fully connected and dropout layers.  Table 4: The table presents the number of runs for which the algorithm incorrectly classified each dataset. The objective of API was to discriminate between regression and classifica- tion datasets. For each dataset we performed 20 API runs. A perfect accuracy of 100% was achieved on 7 datasets. For the types, 'D' represents data classification, 'R' for regression, 'IC' for image classification and 'SA' for sentiment analysis.Some of the other chromosomes in the other runs for CIFAR-10 evolved similar architectures, but this was not always the case. For example, in one particular run, the evolved architecture was: [0, 0, 0, 2, 2, 2, 2, 0, 0, 1]. In this case, the architecture was primarily made up of dropout and convolutional layers -there was only one fully connected layer. For certain runs, the evolved architectures were made up of deep networks containing only fully connected layers. For example, from the appendix, consider the chromosome presented for the Sensorless Drive dataset; the architecture was [1, 1,  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1].The number of epochs used throughout the optimisation of the neural networks was small. It would thus be of interest to extend this study in order to investigate the architectures which would be generated by using a larger number of epochs. One drawback of API is the computational effort required to obtain the results. It would be of interest to further decrease the population size to determine to which extent it can be reduced whilst retaining its current accuracy in discriminating between classification and regression problems.• Dataset: Isolet5 -Classification Chromosome: Units: 1, Loss: MSE, Activation: softmax, Configuration: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]• Dataset: Letter Recognition -Classification Chromosome: Units: 26, Loss: CCE, Activation: sigmoid, Configuration: [1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1]In our study, we present the Automated Problem Identification (API) algorithm, a genetic algorithm coupled to deep networks to auto- matically determining whether a dataset represents a regression or classification problem. While great effort has been put into improv- ing and proposing new machine learning algorithms, typically the practitioner must still decide on the loss function, neural network architecture, number of units in each layer and select appropriate activation functions prior to the execution of the neural network. We propose API with the goal of moving towards general artificial intelligence and automated machine learning that requires little to no human intervention. API was applied to 20 times each to 16 different datasets drawn from varied problem domains and data characteristics. We find that API correctly identified the problem type with an average accuracy of 96.3% running only a single CPU. Furthermore, API was able to recommend whether to use mean squared error or categorical cross entropy, a suitable number of units in the last layer together with the activation function, and furthermore, recommend a network architecture. Despite not being the primary focus of this study, the proposed algorithm generated interesting and relevant deep architectures.We have already begun working on the next phase of this re- search which is to develop an algorithm which can optimise the entire pipeline for creating deep neural networks; whereby, the goal is simply to provide the algorithm with a dataset (without specifying if the problem is a classification or regression problem) and in return, get a deep neural network which can produce com- petitive results. This would completely remove the human from the pipeline. It would be of interest to determine if the evolved networks could outperform those created by humans. It is clear, with the efforts of various researchers that the machine learning community should steer towards algorithms which are completely automated requiring no human intervention.
