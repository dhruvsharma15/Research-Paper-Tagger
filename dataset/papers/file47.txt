Electronic health records (EHRs) have been widely adopted in some countries such as the United States and represent gold mines of infor- mation for medical research. The majority of EHR data exist in unstructured form such as patient notes (Murdoch and Detsky, 2013). Applying nat- ural language processing on patient notes can im- prove the phenotyping of patients (Ananthakrishnan et al., 2013;Pivovarov and Elhadad, 2015;Halpern et al., 2016), which has many down- stream applications such as the understanding of diseases ( Liao et al., 2015).However, before patient notes can be shared with medical investigators, some types of infor- mation, referred to as protected health informa- tion (PHI), must be removed in order to preserve * These authors contributed equally to this work. patient confidentiality. In the United States, the Health Insurance Portability and Accountability Act (HIPAA) (Office for Civil Rights, 2002) de- fines 18 different types of PHI, ranging from pa- tient names and ID numbers to addresses and phone numbers. The task of removing PHI from a patient note is referred to as de-identification. The essence of de-identification is recognizing PHI in patient notes, which is a form of named-entity recognition (NER).Existing de-identification systems are often rule-based approaches or feature-based machine learning approaches. However, these techniques require additional lead time for developing and fine-tuning the rules or features specific to each new dataset. Meanwhile, recent work using ANNs have yielded state-of-the-art performances with- out using any manual features (Dernoncourt et al., 2016). Compared to the previous systems, ANNs have a competitive advantage that the model can be fine-tuned on a new dataset without the over- head of manual feature development, as long as some labels for the dataset are available.However, it may still be inefficient to mass de- ploy ANN-based de-identification system in prac- tical settings, since creating annotations for pa- tient notes is especially difficult. This is due to the fact that only a restricted set of individuals is authorized to access original patient notes; the annotation task cannot be crowd-sourced, mak- ing it slow and expensive to obtain a large anno- tated corpus. Medical professionals are therefore wary to explore patient notes because of this de- identification barrier, which considerably hampers medical research.In this paper, we analyze to what extent trans- fer learning may improve de-identification perfor- mances on datasets with a limited number of la- bels. By training an ANN model on a large dataset (MIMIC) and transferring it to smaller datasets (i2b2 2014 and i2b2 2016), we demonstrate that transfer learning allows to outperform the state-of- the-art results.nating the outputs of the token embedding layer and the character LSTM layer, and outputs a se- quence of vectors.Transfer learning has been studied for a long time. There is no standard definition of transfer learning in the literature (Li, 2012). We follow the defini- tion from (Pan and Yang, 2010): transfer learning aims at performing a task on a target dataset using some knowledge learned from a source dataset. The idea has been applied to many fields such as speech recognition ( Wang and Zheng, 2015) and finance ( Stamate et al., 2015).The successes of ANNs for many applications over the last few years have escalated the interest in studying transfer learning for ANNs. In par- ticular, much work has been done for computer vision ( Yosinski et al., 2014;Oquab et al., 2014;Zeiler and Fergus, 2014). In these studies, some of the parameters learned on the source dataset are used to initialize the corresponding parameters of the ANNs for the target dataset.Fewer studies have been performed on transfer learning for ANN-based models in the field of nat- ural language processing. For example, Mou et al. (2016) focused on transfer learning with con- volutional neural networks for sentence classifica- tion. To the best of our knowledge, no study has analyzed transfer learning for ANN-based models in the context of NER.5. Fully connected layer takes the output of the token LSTM layer as input, and outputs vec- tors containing the scores of each label for the corresponding tokens.6. Sequence optimization layer takes the se- quence of vectors from the output of the fully connected layer and outputs the most likely se- quence of predicted labels, by optimizing the sum of unigram label scores as well as bigram label transition scores. Figure 1 shows how these six components are in- terconnected to form the model. All layers are learned jointly using stochastic gradient descent. For regularization, dropout is applied before the token LSTM layer, and early stopping is used on the development set with a patience of 10 epochs. 4. Token LSTM layer takes as input a sequence of token vectors, which are formed by concate-   The goal of transfer learning is to leverage the information present in a source dataset to im- prove the performance of an algorithm on a target dataset. In our setting, we apply transfer learning by training the parameters of the ANN model on the source dataset (MIMIC), and using the same ANN to retrain on the target dataset (i2b2 2014 or 2016) for fine-tuning. We use MIMIC as the source dataset since it is the dataset with the most labels. We perform two sets of experiments to gain insights on how effective transfer learning is and which parameters of the ANN are the most impor- tant to transfer. 1Experiment 1 Quantifying the impact of trans- fer learning for various train set sizes of the target dataset. The primary purpose of this experiment is to assess to what extent transfer learning improves the performances on the target dataset. We exper- iment with different train set sizes to understand how many labels are needed for the target dataset 1 Our code is an extension of the NER library NeuroNER (Dernoncourt et al., 2017), which we commit- ted to NeuroNER's repository https://github.com/ Franck-Dernoncourt/NeuroNER Experiment 1 Figure 2 compares the F1-scores of the ANN trained only on the target dataset against the ANN trained on the source dataset fol- lowed by the target dataset. Transfer learning im- proves the F1-scores over training only with the target dataset, though the improvement diminishes as the number of training samples used for the tar- get dataset increases. This implies that the rep- resentations learned from the source dataset are efficiently transferred and exploited for the target dataset.Therefore, when transfer learning is adopted, fewer annotations are needed to achieve the same level of performance as when the source dataset is unused. For example, on the i2b2 2014 dataset, performing transfer learning and using 16% of the i2b2 train set leads to similar performance as not using transfer learning and using 34% of the i2b2 train set. Transfer learning thus allows to cut by half the number of labels needed on the target dataset in this case.For both the i2b2 2014 and 2016 datasets, the performance gains from transfer learning are greater when the train set size of the target dataset is small. The largest improvement can be observed for i2b2 2014 when using 5% of the dataset as the train set (consisting of around 2k PHI tokens out of 50k tokens), where transfer learning increases the F1-score by around 3.1 percent point, from 90.12 to 93.21. Even when all of the train set is used, the F1-score improves when using transfer learn- ing, albeit by just 0.17 percent point, from 97.80 to 97.97. Figure 3: Impact of transferring the parameters up to each layer of the ANN model using various train set sizes on the target dataset: 5%, 10%, 20%, 40%, and 60% (official train set).Experiment 2 Figure 3 shows the importance of each layer of the ANN in transfer learning. We observe that transferring a few lower layers is al- most as efficient as transferring all layers. For i2b2 2014, transferring up to the token LSTM shows great improvements for each layer, but there is less improvement for each added layer beyond that. For i2b2 2016, larger improvements can be ob- served up to the character LSTM and less so be- yond that layer. The parameters in the lower layers therefore seems to contain most information that are rele- vant to the de-identification task in general, which supports the common hypothesis that higher layers of ANN architectures contain the parameters that are more specific to the task as well as the dataset used for training.Despite the observation that transferring a few lower layers may be sufficient for efficient trans- fer learning, it is interesting to see that adding the topmost layers to the transfer learning does not hurt the performance. When retraining the model on the target dataset, the ANN is able to adapt to the target dataset quite well despite some the higher layers being initialized to parameters that are likely to be more specific to the source dataset.In this work, we have studied transfer learning with ANNs for NER, specifically patient note de-identification, by transferring ANN parameters trained on a large labeled dataset to another dataset with limited human annotations. We demonstrated that transfer learning improves the performance over the state-of-the-art results on two datasets. Transfer learning may be especially beneficial for a target dataset with small number of labels.
