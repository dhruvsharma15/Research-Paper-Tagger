The computer vision community has witnessed a se- ries of breakthroughs over the past several years. What lies behind this remarkable progress is the advancement in Convolutional Neural Networks (CNNs) [14,13]. From AlexNet [13], VGG [21], GoogLeNet [23], to ResNet [7], we have come a long way in improving the network design, which also results in substantial performance improvement. Take ILSVRC [4] for example, the classification error rate has dropped from 15.3% to below 3% in just a few years, primarily thanks to the evolution of network architectures. Nowadays, "using a better network" has become a com- monly adopted strategy to boost performance -this strat- egy, while simple, has been repeatedly shown to be very effective in practical applications, e.g. recognition [4], de- tection [17], and segmentation [6].However, improving network designs is non-trivial. Along this way, we are facing two key challenges, namely, * Work done during an internship at SenseTime the large design space and the costly training process. Specifically, to devise a convolutional network, one has to make a number of modeling choices, e.g. the number of layers, the number of channels within these layers, and whether to insert a pooling layer at certain points, etc. All such choices together constitute a huge design space that is simply beyond our means to conduct a thorough investiga- tion. Previous efforts were mostly motivated by intuitions - though fruitful in early days, this approach has met increas- ing difficulties as networks become more complicated.In recent works [27,1,28,26], automatic search meth- ods have been proposed. These methods seek better designs (within a restricted design space), by gradually adjusting parts of the networks and validating the generated designs on real datasets. Without an effective prior guidance, such search procedures tend to spend lots of resources in eval- uating "unpromising" options. Also note that training a network in itself is a time-consuming process. Even on a dataset of moderate size, it may take hours (if not days) to train a network. Consequently, an excessively long process is generally needed to to find a positive adjustment. It's been reported [27,28] that searching a network on CIFAR takes hundreds of GPUs for a lengthy period.Like many others in this community, we have our own share of painful experience in finding good network de- signs. To mitigate this lengthy and costly process, we de- velop an approach to quantitatively assess an architecture before investing resources in training it. More accurately, we propose a model, called Peephole, to predict the final performance of an architecture before training.In this work, we explore a natural idea, that is, to for- mulate the network performance predictor as a regression model, which accepts a network architecture as the input and produces a score as a predictive estimate of its perfor- mance, e.g. the accuracy on the validation set. Here, the foremost question is how to turn a network architecture into a numerical representation. This is nontrivial given the diversity of possible architectures. We tackle this prob- lem in two stages. First, we develop a vector representa- tion, called Unified Layer Code, to encode individual lay- ers. This scheme allows various layers to be represented uniformly and effectively by vectors of a fixed dimension. Second, we introduce an LSTM network to integrate the layer representations, which allows architectures with dif- ferent depths and topologies to be handled in a uniform way.Network Design. Since the debut of AlexNet [13], CNNs have become widely adopted to solve computer vision prob- lems. Over the past several years, the advances in network design have been a crucial driving force behind the progress in computer vision. Many representative architectures, such as AlexNet [13], VGGNet [21], GoogLeNet [23], ResNet [7], DenseNet [9], and DPN [3] are designed man- ually, based on intuitions and experience. Nonetheless, this approach has become less rewarding. The huge design space combined with the costly training procedure makes it increasingly difficult to obtain an improved design.Recently, the community has become more interested in an alternative approach, namely automatic network design. Several methods [27,1,28,26] have been proposed. These methods rely on reinforcement learning to learn how to im- prove a network design. In order to supervise the learning process, all these methods rely on actual training processes to provide feedback, which are very costly, in both time and computational resources. Our work differs essentially. In- stead of developing an automatic design technique, we fo- cus on a crucial but often overlooked problem, that is, how to quickly get the performance feedback.Another challenge that we face is how to obtain a train- ing set. Note that this task differs essentially from conven- tional ones in that the samples are network architectures to- gether with their performances instead of typical data sam- ples like images or data records. Here, the sample space is huge and it is very expensive to obtain even a sample (which involves running an entire training procedure). In addressing this issue, we draw inspirations from engineer- ing practice, and develop a block-based sampling scheme, which generates new architectures by integrating the blocks sampled from a Markov process. This allows us to explore a large design space with limited budget while ensuring that each sample architecture is reasonable.Overall, our main contributions lie in three aspects: (1) We develop Peephole, a new framework for predicting net- work performance based on Unified Layer Code and Layer Embedding. Our Peephole can predict a network's perfor- mance before training. (2) We develop Block-based Gener- ation, a simple yet effective strategy to generate a diverse set of reasonable network architectures. This allows the proposed performance predictor to be learned with an af- fordable budget. (3) We conducted empirical studies over more than a thousand networks, which show that the pro- posed framework can make reliable predictions for a wide range of network architectures and produce consistent rank- ing across datasets. Hence, its predictions can provide an effective way to search better network designs, as shown in Figure 1.Network Performance Prediction. As mentioned, our approach is to predict network performance. This is an emerging topic, on which existing works remain limited. Some previous methods on performance prediction were developed in the context of hyperparameter optimization, using techniques like Gaussian Process [22] or Last-Seen- Value heuristics [16]. These works mainly focus on de- signing a special surrogate function for a better evaluation of hyper-configurations. There have also been attempts to directly predict network performance. Most works along this line intend to extrapolate the future part of the learning curve given the elapsed part. For this, Domhan et al. [5] pro- posed a mixture of parametric functions to model the learn- ing curve. Klein et al. [11] extended this work by replacing the mixture of functions with a Bayesian Neural Network. Baker et al. [2] furthered this study by additionally leverag- ing the information about network architectures with hand- crafted features, and using v-SVR for curve prediction.All these works rely on partially observed learning curves to make predictions, which still involve a partly run training procedure and therefore are time-consuming. To support large-scale search of network designs, we desire much quicker feedback and thus explore a fundamentally different but more challenging approach, that is, to predict the performance purely based on architectures.Concat Figure 2: The overall pipeline of the Peephole framework. Given a network architecture, it first encodes each layer into a vector through integer coding and layer embedding. Subsequently, it applies a recurrent network with LSTM units to integrate the information of individual layers following the network topology into a structural feature. This structural feature together with the epoch index (also embedded into a vector) will finally be fed to an MLP to predict the accuracy at the corresponding time point, i.e. the end of the given epoch. Note that the blocks indicated by green color, including the embeddings, the LSTM, and the MLP, are jointly learned in an end-to-end manner.called Peephole and shown in Figure 2, can be formalized as a function, denoted by f . The function f takes two argu- ments, a network architecture x and an epoch index t, and produces a scalar value f (x, t) as the prediction of the ac- curacy at the end of the t-th epoch. Here, incorporating the epoch index t as an input to f is reasonable, as the validation accuracy generally changes as the training proceeds. There- fore, when we predict performance, we have to be specific about the time point of the prediction.Note that this formulation differs fundamentally from previous works [5,11,2]. Such methods require the obser- vation of the initial part (usually 25%) of the training curve and extrapolate the remaining part. On the contrary, our method aims to predict the entire curve, relying only on the network architecture. In this way, it can provide feedback much quicker and thus is particularly suited for large-scale search of network designs.However, developing such a predictor is nontrivial. To- wards this goal, we are facing significant technical chal- lenges, e.g. how to unify the representation of various lay- ers, and how to integrate the information from individual layers over various network topologies. In what follows, we will present our answers to these questions. Particularly, Sec. 3.1 presents a unified vector representation of layers, which is constructed in two steps, namely coding and em- bedding. Sec. 3.2 presents an LSTM model for integrating the information across layers. row corresponds to a layer type. For each layer, we encode it with a type id (TY), a kernel width (KW), a kernel height (KH), and a channel number (CH). Note that for CH, we use the ratio of the output channel number to the input number, instead of the absolute value, and quantize it into an integer.paper, we propose Unified Layer Code (ULC), a uniform scheme to encode various layers into numerical vectors, which is done in two steps: integer coding and embedding.In general, a convolutional neural network can be con- sidered as a directed graph whose nodes represent certain operations, e.g. convolution and pooling. Hence, to develop a representation of such a graph, the first step is to define a representation of individual nodes, i.e. the layers. In this Integer coding. We notice that the operations commonly used in a CNN, including convolution, pooling, and nonlin- ear activation, can all be considered as applying a kernel to the input feature map. To produce an output value, the ker- nel takes a local part of the feature map as input, applies a linear or nonlinear transform, and then yields an output. In particular, an element-wise activation function can be con- sidered as a nonlinear kernel of size 1 × 1.Each operation is also characterized by the number of output channels. In a typical CNN, the number of chan- nels can vary significantly, from below 10 to thousands. However, for a specific layer, this number is usually de- cided based on that of the input, according to a ratio within a limited range. Particularly, for both pooling and nonlin- ear activation, the numbers of output channels are always equal to that of the input channels, and thus the ratio is 1. While for convolution, the ratio usually ranges from 0.25 to 3, depending on whether the operation intends to reduce, preserve, or expand the representation dimension. In light of this, we choose to represent CH by the output-input ratio instead of the absolute number. In this way, we can effec- tively limit its dynamic range, quantize it into 8 bins (re- spectively centered at 0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 2.5, 3.0).Overall, we can represent a common operation by a tuple of four integers in the form of (TY, KW, KH, CH), where TY is an integer id that indicates the type of the computation, KW and KH are respectively the width and height of the kernel, while CH represents the ratio of output-input chan- nels (using the the index of the quantized bin). The details of this scheme are summarized in Table 1. work. In this work, we focus on the networks with sequen- tial structures, which already constitute a significant portion of the networks used in real-world practice. Here, the chal- lenge is how to cope with varying depths in a uniform way.Inspired by the success of recurrent networks in sequen- tial modeling, e.g. in language modeling [19] and video an- alytics [25], we choose to explore recurrent networks in our problem. Specifically, we adopt the Long-Short Term Mem- ory (LSTM) [8], an effective variant of RNN, for integrating the information along a sequence of layers. In particular, an LSTM network is composed of a series of LSTM units, each for a time step (i.e. a layer in our context). The LSTM maintains a hidden state h t and a cell memory c t , and uses an input gate i t , an output gate o t , and a forget gate f t to control the information flow. At each step, it takes an input x t , decides the value of all the gates, yields an output u t , and updates both the hidden state h t and the cell memory c t , as follows:Layer embedding. While capturing the key information for a layer, the discrete representation introduced above is not amenable to complex numerical computation and deep pattern recognition. Inspired by word embedding [20], a strategy proven to be very effective in natural language pro- cessing, we take one step further and develop Layer Em- bedding, a scheme to turn the integer codes into a unified real-vector representation. As shown in Figure 3, the embedding is done by table lookup. Specifically, this module is associated with three lookup tables, respectively for layer types, kernel sizes, and channel ratios. Note that the kernel size table is used to en- code both KW and KH. Given a tuple of integers, we can convert its element into a real vector by retrieving from the corresponding lookup table. Then by concatenating all the embedded vectors derived respectively from individual in- tegers, we can form a vector representation of the layer.Here, σ denotes the sigmoid function while the element- wise product. Along the way from low-level to high-level layers, the LSTM network would gradually incorporate layer-wise information into the hidden state. At the last step, i.e. the layer right before the fully connected layer for classification, we extract the hidden state of the LSTM cell to represent the overall structure of the network, which we refer to as the structural feature.As shown in Figure 2, the Peephole framework will fi- nally combine this structural feature with the epoch index (also embedded into a real-vector) and use a Multi-Layer Perceptron (MLP) to make the final prediction of accuracy. In particular, the MLP component at the final step is com- prised of three fully connected layers with Batch Normal- ization and ReLU activation. The output of this component is a real value that serves as an estimate of the accuracy.With the layer-wise representations based on Unified Layer Code and Layer Embedding, the next is to aggre- gate them into an overall representation for the entire net- Like other predictive models, Peephole requires suffi- cient training samples to learn its parameters. However, for our problem, the preparation of the training set itself is a challenge. Randomly sampling sequences of layers is not a viable solution for two reasons: (1) The design space grows exponentially as the number of layers increases, while it is expensive to obtain a training sample (which requires run- ning an entire training procedure to obtain a performance curve). Hence, it is unaffordable to explore the entire design space freely, even with a large amount of computational re- sources. (2) Many combinations of layers are not reason- able options from a practical point of view (e.g. a network with multiple activation layers stacked consecutively in a certain part of the layer sequence). Training such networks are simply a waste of resources. In this section, we draw inspirations from existing prac- tice and propose a Block-based Generation scheme to ac- quire training samples in Sec. 4.1. Then, we present a learn- ing objective for supervising the training process in Sec. 4.2. types, which are empirically estimated from practical net- works. For example, a convolution layer has a high chance to be followed by a batch normalization layer and a nonlin- ear activation. An activation layer is more likely to ensued by another convolution layer or a pooling layer. More de- tails will be provided in the supplemental materials.With a collection of blocks, we can then build a complete network by assembling them following a skeleton. The de- sign of the skeleton follows the general practice in computer vision. As shown in Figure 4, the skeleton comprises three stages with different resolutions. Each stage is a stack of blocks followed by a max pooling layer to reduce the spatial resolution. The features from the last block will go through an average pooling layer and then a linear layer for clas- sification. When replicating blocks within a stage, 1 × 1 convolution layers will be inserted in between for dimen- sion adaptation when the output dimension of the preceding layer does not match the input dimension of the next layer.The block-based generation scheme presented above ef- fectively constrain the sample space, ensuring that the gen- erated networks are mostly reasonable and making it feasi- ble to prepare a training set with an affordable budget.Given a set of sample networks {x i } 1:N , we can obtain a performance curves y i (t) for each network x i , i.e. the vali- dation accuracy as a function of epoch numbers, by training the network on a given dataset. Hence, we can obtain a set of pairs D = {(x i , y i )} 1:N and learn the parameters of the predictor in a supervised way.Specifically, we formulate the learning objective with the smooth L1 loss, denoted by l, as below:The engineering practice of network design [7,24] sug- gests that it is a good strategy to construct a neural net- work by stacking blocks that are structurally alike. Zoph et al. [28] and Zhong et al. [26] also proposed to search transferable blocks (referred to as cells in [28]) and assem- ble them into a network in their efforts towards an automatic way for network search. Inspired by these works, we pro- pose Block-based Generation, a simple yet effective strat- egy to prepare our training samples. As illustrated in Fig- ure 3, it first designs individual blocks and then stacks them into a network following a certain skeleton.A block is defined to be a short sequence of layers with no more than 10 layers. To generate a block, we fol- low a Markov chain. Specifically, we begin with a con- volution layer by randomly choosing its kernel size from {1, . . . , 5} and the ratio of output/input channel numbers from {0.25, 0.50, 0.75, 1.0, 1.5, 2.0, 2.5, 3.0}. Then at each step, we draw the next layer conditioned on the current one following predefined transition probabilities between layerHere, θ denotes the predictor parameters. Note that we train each sample network with T epochs, and use the results of the final epoch to supervise the learning process. Our framework is very flexible -with the entire learning curves, in principle, one can use the results at multiple epochs for training. However, we found empirically that using only the final epochs already yields reasonably good results.First, the Peephole predictor is task-specific. It is trained to predict the performance on a certain dataset with a spe- cific performance metric. Second, besides network archi- tectures and epoch numbers, the performance of a network also depends on a number of other factors, e.g. how it is ini- tialized, how the learning rate is adjusted over time, as well as the settings on the optimizers. In this work, we train all sample networks with a fixed set of or such design choices. in Sec. 4 to generate two sets of networks, respectively for CIFAR-10 and MNIST, and train them to obtain perfor- mance curves. Admittedly, such a setting may sound a bit restrictive. However, this actually reflects our typical practice when tuning network designs in ablation studies. Moreover, most automatic network search schemes also fix such choices during the search process in order to fairly compare among architectures. Therefore, the predictor trained in this way can already provide good support to the practice. That be- ing said, we do plan to incorporate additional factors in the predictor in our future exploration.Detailed settings. For fair comparison, we train all sam- pled networks with the same setting: We use SGD with mo- mentum 0.9 and weight decay 0.0001. Each epoch loops over the entire training set in random order. The learn- ing rate is initialized to 0.1 and scaled down by a factor of 0.1 every 60 epochs (for CIFAR-10) or 80 epochs (for MNIST). The network weights are all initialized following the scheme in [7]. Table 2 shows the statistics of these net- works and their performances.For the Peephole model, we use 40-dimensional vectors for both layer embedding and epoch embedding. The di- mension of the hidden states in LSTM is set to 160. The Multi-Layer Perceptron (MLP) for final prediction com- prises 3 linear layers, each with 200 hidden units.Methods to compare. We compare our Peephole method with two representative methods in recent works:We tested Peephole, the proposed network performance prediction framework on two public datasets, CIFAR- 10 [12] and MNIST [15]. Sec. 5.1 presents the experiment settings, including how the datasets are used and the im- plementation details of our framework. Sec. 5.2 presents the results we obtained on both datasets, and compares them with other performance prediction methods. Sec. 5.3 presents preliminary results on using Peephole to guide the search of better networks on ImageNet. Finally, Sec. 5.4 presents a qualitative study on the learned representations via visualization.1. Bayesian Neural Network (BNN) [11]. This method is devised to extrapolate learning curves given their ini- tial portions (usually 25% of the entire ones). It repre- sents each curve as a linear combination of basis func- tions and uses Bayesian Neural Network to yield prob- abilistic extrapolations.2. ν-Support Vector Regression (ν-SVR) [2]. This method relies on a regression model, ν-SVR, to make predic- tions. To predict the performance of a network this model takes as input both the initial portion of the learning curve and simple heuristic features derived based on the network architecture. This method rep- resents the state of the art on this task.Note that both methods above require the initial portions of the learning curves while ours can give feedback purely based on the network architecture before training.Datasets. CIFAR-10 [12] is a dataset for object classifi- cation. In recent years, it usually serves as the testbed for convolutional network designs. MNIST [15] is a dataset for hand-written digit classification, one of the early and widely used datasets for neural network research. Both datasets are of moderate scale. We chose them as the basis for our study because it is affordable for us to train over a thou- sand networks thereon to investigate the effectiveness of the proposed predictor. After all, our goal is to explore an performance prediction method that works with diverse ar- chitectures instead of pursing a state-of-the-art network on large-scale vision benchmarks. To prepare the samples for training and validation, we follow the procedure described Evalution criteria. We evaluate the predictor perfor- mances using three criteria:1. Mean Square Error (MSE), which directly measures the deviation of the predictions from the actual values.2. Kendall's Tau (Tau), which measures the correlation between the predictive rankings among all testing networks and their actual rankings. The value of Kendall's Tau ranges from −1 to 1, and a higher value indicates higher correlation.3. Coefficient of Determination (R 2 ), which measures how closely the predicted value depends on the actual     trained on CIFAR-10, with three metrics MSE, Tau, and R 2 . The best result for each metric is highlighted with bold font.  Results on CIFAR-10. Table 3 compares the prediction results for the networks trained on CIFAR-10, obtained with different predictors. We observe that Peephole consistently outperforms both BNN and ν-SVR across all metrics. Par- ticularly, achieving smaller MSE means that the predictions from Peephole are generally more accurate than those from others. This makes it a viable predictor in practice. On the other hand, the high values in Tau and R 2 indicate that the ranking among multiple networks produced by Peep- hole is quite consistent with the ranking of their actual per- formances. This makes Peephole a good criterion to select performant network architectures.The scatter plots in Figure 5 visualize the correlations between the predicted accuracies and actual accuracies, ob- tained with different methods. Qualitatively, the predictions made by Peephole demonstrate notably higher correlation with the actual values than those from other methods, espe- cially at the high-accuracy area (top right corner).Results on MNIST. We also evaluated the predictions on the networks trained on MNIST in the same way, with the results shown in Table 4. Note that since most networks can yield high accuracies on this MNIST, it would be easier to produce more precise predictions on the accuracy numbers but more difficult to yield consistent rankings. This is re- flected by the performance metrics in the table. Despite this difference in data characteristics, Peephole still significantly outperforms the other two methods across all metrics.Getting top performance on ImageNet is a holy grail for convolutional network design. Yet, directly training Peep- hole based on ImageNet is prohibitively expensively due to the lengthy processes of training a network on ImageNet. Nevertheless, [28] suggests an alternative way, that is, to search for scalable and transferable block architectures on a smaller dataset like CIFAR-10. Following this idea, we select the network architecture with the highest Peephole- predicted accuracy among those in our validation set for CIFAR-10, then scale it up and transfer it to ImageNet 1 . We compared this network with VGG-13 [21], a widely used network that was designed manually. From the results in Table 5, we can see that the selected network achieves moderately better accuracy on ImageNet with a substan- tially smaller parameter size. This is just a preliminary study. But it shows that Peephole is promising for pursu- ing performant network designs that are transferable to the larger datasets.The effective of Peephole may be attributed to its abil- ity to abstract a uniform but expressive representation for various architectures. To gain better understanding of this In one study, we examined the hidden cells inside the LSTM using the method presented in [10]. Particularly, we recorded the dynamics of the cell responses as the LSTM traverses the sequence of layers. Figure 6 shows the re- sponses of a certain cell, where we can see that the re- sponse raises every time it gets to a convolution layer. This behavior is observed in different blocks. This observation suggests that this cell learns to "detect" convolution layers even without being explicitly directed to do. In a certain sense, this also reflects the capability of LSTM to capture architectural patterns.In another study, we visualized the structural feature (de- rived from the last unit of the LSTM) using t-SNE embed- ding [18]. Figure 7 shows the visualized results. We can see the gradual transition from low performance networks to high performance networks. This shows that the struc- tural features contain key information related to the network performances. studies with over a thousand networks trained on CIFAR- 10 and MNIST showed that the proposed method can yield reliable predictions that are highly correlated with the ac- tual performance. On three different metrics, our method significantly outperforms previous methods.We note that this is just the first step towards the goal of fast search of network designs. In future work, we plan to incorporate additional factors in our predictor, such as various design choices, to extend the applicability of the predictive model. We will also explore more effective ways to optimize network designs on top of this predictive model.We presented Peephole, a predictive model for predicting network performance based on architectures before train- ing. Specifically, we developed Unified Layer Code as a unified representation for network architectures and a LSTM-based model to integrate the information from in- dividual layers. To tackle the difficulties in preparing the training set, we propose a Block-based Generation scheme, which allows us to explore a wide variety of reasonable de- signs while constraining the search space. The systematic Here we detail our con- figurations for Block-based Generation scheme. The whole process begins with a convolution layer whose kernel size is uniformly sampled from {1, . . . , 5} and the ratio of output/input channel number is uniformly sampled from {0.25, 0.50, 0.75, 1.0, 1.5, 2.0, 2.5, 3.0}. Then the con- struction will follow a Markov chain, i.e. we will choose the type of the next layer merely based on the current one. The transition matrix is shown in Table 1. Note that Batch Normalization is inserted right behind Convolution layers with the probability of 0.6. Thus it's not shown in the ta- ble. Meanwhile, for computational consideration, we limit the depth of a block to less than 11 layers and restrict the number of convolution layers within a block to less than 4. Figure 1: Selected Architecture for ImageNet. On the left is the block architecture selected based on Peephole-predicted accuracy. We mark the type of each layer. For Convolution layers, we also note the kernel size (W idth × Height) and the ratio of output/input channel sizes (the last digit). On the right is the scheme we use to stack replicants of the left block into a network, which achieves 71.91% Top-1 accu- racy.Selected Block for ImageNet. In Figure 1, we illustrate the selected block architecture based on Peephole-predicted accuracy. We also stack them in a similar manner to our scheme used in CIFAR-10. Note that this architecture is not generated by our algorithm but selected from randomly sampled validation architectures using Peephole.  
