There is a surge of research interest in deep generative models ( Hu et al., 2017), such as Variational Autoencoders (VAEs) (Kingma &amp; Welling, 2013), Generative Adver- sarial Nets (GANs) ( Goodfellow et al., 2014), and auto- regressive models (van den Oord et al., 2016). Despite their impressive advances in visual domain, such as image gen- eration ( Radford et al., 2015), learning interpretable image representations ( Chen et al., 2016), and image editing ( Zhu et al., 2016), applications to natural language generation have been relatively less studied. Even generating realis- tic sentences is challenging as the generative models are A first challenge comes from the discrete nature of text samples. The resulting non-differentiability hinders the use of global discriminators that assess generated samples and back-propagate gradients to guide the optimization of gen- erators in a holistic manner, as shown to be highly effective in continuous image generation and representation model- ing Larsen et al., 2016;Dosovitskiy &amp; Brox, 2016). A number of recent approaches attempt to ad- dress the non-differentiability through policy learning ( Yu et al., 2017) which tends to suffer from high variance dur- ing training, or continuous approximations ( Zhang et al., 2016;Kusner &amp; Hernndez-Lobato, 2016) where only pre- liminary qualitative results are presented. As an alterna- tive to the discriminator based learning, semi-supervised VAEs ( Kingma et al., 2014) minimize element-wise recon- struction error on observed examples and are applicable to discrete visibles. This, however, loses the holistic view of full sentences and can be inferior especially for modeling global abstract attributes (e.g., sentiment). Another challenge for controllable generation relates to learning disentangled latent representations. Interpretabil- ity expects each part of the latent representation to govern and only focus on one aspect of the samples. Prior meth- ods ( Chen et al., 2016;Odena et al., 2016) on structured representation learning lack explicit enforcement of the in-dependence property on the full latent representation, and varying individual code may result in unexpected variation of other unspecified attributes besides the desired one.In this paper, we propose a new text generative model that addresses the above issues, permitting highly disen- tangled representations with designated semantic structure, and generating sentences with dynamically specified at- tributes. We base our generator on VAEs in combination with holistic discriminators of attributes for effective im- position of structures on the latent code. End-to-end opti- mization is enabled with differentiable softmax approxima- tion which anneals smoothly to discrete case and helps fast convergence. The probabilistic encoder of VAE also func- tions as an additional discriminator to capture variations of implicitly modeled aspects, and guide the generator to avoid entanglement during attribute code manipulation.Our model can be interpreted as enhancing VAEs with an extended wake-sleep procedure (Hinton et al., 1995), where the sleep phase enables incorporation of generated samples for learning both the generator and discriminators in an alternating manner. The generator and the discrim- inators effectively provide feedback signals to each other, resulting in an efficient mutual bootstrapping framework. We show a little supervision (e.g., 100s of annotated sen- tences) is sufficient to learn structured representations.Besides efficient representation learning and enabled semi- supervised training, another advantage of using discrimi- nators as learning signals for the generator, as compared to conventional conditional reconstruction based meth- ods ( Wen et al., 2015;Kingma et al., 2014), is that dis- criminators of different attributes can be trained indepen- dently. That is, for each attribute one can use separate labeled data for training the respective discriminator, and the trained discriminators can be combined arbitrarily to control a set of attributes of interest. In contrast, recon- struction based approaches typically require every instance of the training data to be labeled exhaustively with all tar- get attributes (Wen et al., 2015), or to marginalize out any missing attributes ( Kingma et al., 2014) which can be com- putationally expensive.Remarkable progress has been made in deep generative modeling. Hu et al. (2017) provide a unified view of a diverse set of deep generative methods. Variational Au- toencoders (VAEs) (Kingma &amp; Welling, 2013) consist of encoder and generator networks which encode a data exam- ple to a latent representation and generate samples from the latent space, respectively. The model is trained by maxi- mizing a variational lower bound on the data log-likelihood under the generative model. A KL divergence loss is mini- mized to match the posterior of the latent code with a prior, which enables every latent code from the prior to decode into a plausible sentence. Without the KL regularization, VAEs degenerate to autoencoders and become inapplicable for the generic generation. The vanilla VAEs are incom- patible with discrete latents as they hinder differentiable parameterization for learning the encoder. Wake-sleep al- gorithm (Hinton et al., 1995) introduced for learning deep directed graphical models shares similarity with VAEs by also combining an inference network with the generator. The wake phase updates the generator with samples gener- ated from the inference network on training data, while the sleep phase updates the inference network based on sam- ples from the generator. Our method combines VAEs with an extended wake-sleep in which the sleep procedure up- dates both the generator and inference network (discrimi- nators), enabling collaborative semi-supervised learning.As a showing case, we apply our model to generate sen- tences with controlled sentiment and tenses. Though to our best knowledge there is no text corpus with both senti- ment and tense labels, our method enables to use separate datasets, one with annotated sentiment and the other with tense labels. Quantitative experiments demonstrate the ef- ficacy of our method. Our model improves over previous generative models on the accuracy of generating specified attributes as well as performing classification using gen- erated samples. We show our method learns highly dis- entangled representations from only word-level labels, and produces plausible short sentences.Besides reconstruction in raw data space, discriminator- based metric provides a different way for generator learn- ing, i.e., the discriminator assesses generated samples and feedbacks learning signals. For instance, GANs (Goodfellow et al., 2014) use a discriminator to feedback the probability of a sample being recognized as a real exam- ple. Larsen et al. (2016) combine VAEs with GANs for enhanced image generation. Dosovitskiy &amp; Brox (2016); Taigman et al. (2017) use discriminators to measure high- level perceptual similarity. Applying discriminators to text generation is hard due to the non-differentiability of dis- crete samples ( Yu et al., 2017;Zhang et al., 2016;Kusner &amp; Hernndez-Lobato, 2016  InfoGAN (Chen et al., 2016), which resem- bles the extended sleep procedure of our joint VAE/wake- sleep algorithm, disentangles latent representation in an un- supervised manner. The semantic of each dimension is observed after training rather than designated by users in a controlled way. Siddharth et al. (2017); Kingma et al. (2014) base on VAEs and obtain disentangled image rep- resentations with semi-supervised learning. Zhou &amp; Neu-big (2017) extend semi-supervised VAEs for text transduc- tion. In contrast, our model combines VAEs with discrim- inators which provide a better, holistic metric compared to element-wise reconstruction. Moreover, most of these ap- proaches have only focused on the disentanglement of the structured part of latent representations, while ignoring po- tential dependence of the structured code with attributes not explicitly encoded. We address this by introducing an in- dependency constraint, and show its effectiveness for im- proved interpretability.í µí± § í µí± Generator í µí±¥ $ Encoder í µí±¥ Discriminators Figure 1. The generative model, where z is unstructured latent code and c is structured code targeting sentence attributes to con- trol. Blue dashed arrows denote the proposed independency con- straint (section 3.2 for details), and red arrows denote gradient propagation enabled by the differentiable approximation.Our model aims to generate plausible sentences condi- tioned on representation vectors which are endowed with designated semantic structures. For instance, to control sentence sentiment, our model allocates one dimension of the latent representation to encode "positive" and "nega- tive" semantics, and generates samples with desired sen- timent by simply specifying a particular code. Benefiting from the disentangled structure, each such code is able to capture a salient attribute and is independent with other fea- tures. Our deep text generative model possesses several merits compared to prior work, as it 1) facilitates effective imposition of latent code semantics by enabling global dis- criminators to guide the discrete text generator learning; 2) improves model interpretability by explicitly enforcing the constraints on independent attribute controls; 3) per- mits efficient semi-supervised learning and bootstrapping by synthesizing variational auto-encoders with a tailored wake-sleep approach. We first present the overview of our framework ( §3.1), then describe the model in detail ( §3.2).Thus, for each attribute code in c, we set up an individ- ual discriminator to measure how well the generated sam- ples match the desired attributes, and drive the generator to produce improved results. The difficulty of applying dis- criminators in our context is that text samples are discrete and non-differentiable, which breaks down gradient prop- agation from the discriminators to the generator. We use a continuous approximation based on softmax with a de- creasing temperature, which anneals to the discrete case as training proceeds. This simple yet effective approach en- joys low variance and fast convergence.We build our framework starting from variational auto- encoders ( §2) which have been used for text genera- tion ( Bowman et al., 2015), where sentencê x is generated conditioned on latent code z. The vanilla VAE employs an unstructured vector z in which the dimensions are entan- gled. To model and control the attributes of interest in an interpretable way, we augment the unstructured variables z with a set of structured variables c each of which targets a salient and independent semantic feature of sentences.Intuitively, having an interpretable representation would imply that each structured code in c can independently control its target feature, without entangling with other at- tributes, especially those not explicitly modeled. We en- courage the independency by enforcing those irrelevant at- tributes to be completely captured in the unstructured code z and thus be separated from c that we will manipulate. To this end, we reuse the VAE encoder as an additional discriminator for recognizing the attributes modeled in z, and train the generator so that these unstructured attributes can be recovered from the generated samples. As a result, varying different attribute codes will keep the unstructured attributes invariant as long as z is unchanged.We want our sentence generator to condition on the com- bined vector (z, c), and generate samples that fulfill the attributes as specified in the structured code c. Conditional generation in the context of VAEs (e.g., semi-supervised VAEs ( Kingma et al., 2014)) is often learned by recon- structing observed examples given their feature code. How- ever, as demonstrated in visual domain, compared to com- puting element-wise distances in the data space, computing distances in the feature space allows invariance to distract- ing transformations and provides a better, holistic metric. Figure 1 shows the overall model structure. Our complete model incorporates VAEs and attribute discriminators, in which the VAE component trains the generator to recon- struct real sentences for generating plausible text, while the discriminators enforce the generator to produce attributes coherent with the conditioned code. The attribute discrim- inators are learned to fit labeled examples to entail desig- nated semantics, as well as trained to explain samples from the generator. That is, the generator and the discrimina- tors form a pair of collaborative learners and provide feed- back signals to each other. The collaborative optimization resembles wake-sleep algorithm. We show the combined VAE/wake-sleep learning enables a highly efficient semi- supervised framework, which requires only a little supervi- sion to obtain interpretable representation and generation.We now describe our model in detail, by presenting the learning of generator and discriminators, respectively.The generator G is an LSTM-RNN for generating token sequencê x = {ˆx{ˆx 1 , . . . , ˆ x T } conditioned on the latent code (z, c), which depicts a generative distribution:t wherê x &lt;t indicates the tokens precedingˆxprecedingˆ precedingˆx t . The gener- ation thus involves a sequence of discrete decision mak- ing which samples a token from a multinomial distribution parametrized using softmax function at each time step t: the objectives described shortly. Besides the reconstruc- tion loss which drives the generator to produce realistic sentences, the discriminator provides extra learning signals which enforce the generator to produce coherent attribute that matches the structured code in c. However, as it is impossible to propagate gradients from the discriminator through the discrete samples, we resort to a deterministic continuous approximation. The approximation replaces the sampled tokenˆxtokenˆ tokenˆx t (represented as a one-hot vector) at each step with the probability vector in Eq. (2) which is differ- entiable w.r.t the generator's parameters. The probability vector is used as the output at the current step and the input to the next step along the sequence of decision making. The resulting "soft" generated sentence, denoted as G τ (z, c), is fed into the discriminator 1 to measure the fitness to the tar- get attribute, leading to the following loss for improving G:where o t is the logit vector as the inputs to the softmax function, and τ &gt; 0 is the temperature normally set to 1.The unstructured part z of the representation is modeled as continuous variables with standard Gaussian prior p(z), while the structured code c can contain both continu- ous and discrete variables to encode different attributes (e.g., sentiment categories, formality) with appropriate prior p(c). Given observation x, the base VAE includes a conditional probabilistic encoder E to infer the latents z:The temperature τ (Eq.2) is set to τ → 0 as training pro- ceeds, yielding increasingly peaked distributions that fi- nally emulate discrete case. The simple deterministic ap- proximation effectively leads to reduced variance and fast convergence during training, which enables efficient learn- ing of the conditional generator. The diversity of genera- tion results is guaranteed since we use the approximation only for attribute modeling and the base sentence genera- tion is learned through VAEs.Let θ G and θ E denote the parameters of the generator G and the encoder E, respectively. The VAE is then opti- mized to minimize the reconstruction error of observed real sentences, and at the same time regularize the encoder to be close to the prior p(z):where KL(···) is the KL-divergence; and q D (c|x) is the conditional distribution defined by the discriminator D for each structured variable in c:With the objective in Eq.(6), each structured attribute of generated sentences is controlled through the correspond- ing code in c and is independent with other variables in the latent representation. However, it is still possible that other attributes not explicitly modeled may also entangle with the code in c, and thus varying a dimension of c can yield unex- pected variation of these attributes we are not interested in.To address this, we introduce the independency constraint which separates these attributes with c by enforcing them to be fully captured by the unstructured part z. Therefore, besides the attributes explicitly encoded in c, we also train the generator so that other non-explicit attributes can be correctly recognized from the generated samples and match the unstructured code z. Instead of building a new discrim- inator, we reuse the variational encoder E which serves precisely to infer the latents z in the base VAE. The loss is in the same form as with Eq.(6) except replacing the dis- criminator conditional q D with the encoder conditional q E :Here, for notational simplicity, we assume only one struc- tured variable and thus one discriminator, though our model specification can straightforwardly be applied to many attributes. The distribution over (z, c) factors into q E and q D as we are learning disentangled representa- tions. Note that here the discriminator D and code c are not learned with the VAE loss, but instead optimized withNote that, as the discriminator in Eq.(6), the encoder now performs inference over generated samples from the prior, as opposed to observed examples as in VAEs.Combining Eqs.(4)- (7) we obtain the generator objective:where λ c and λ z are balancing parameters. The varia- tional encoder is trained by minimizing the VAE loss, i.e., min θ E L VAE .The discriminator D is trained to accurately infer the sen- tence attribute and evaluate the error of recovering the de- sired feature as specified in the latent code. For instance, for categorical attribute, the discriminator can be formu- lated as a sentence classifier; while for continuous target a probabilistic regressor can be used. The discriminator is learned in a different way compared to the VAE encoder, since the target attributes can be discrete which are not sup- ported in the VAE framework. Moreover, in contrast to the unstructured code z which is learned in an unsupervised manner, the structured variable c uses labeled examples to entail designated semantics. We derive an efficient semi- supervised learning method for the discriminator.Input: A large corpus of unlabeled sentences X = {x} A few sentence attribute labels XL = {(xL, cL)} Parameters: λc, λz, λu, β -balancing parameters 1: Initialize the base VAE by minimizing Eq. (4)   The sleep procedure, corresponding to Eqs.(6)- (7) and (10). Black arrows denote inference and generation; red dashed arrows denote gradient propagation. The two steps in the sleep procedure, i.e., optimizing the discriminator and the gener- ator, respectively, are performed in an alternating manner.Besides, the conditional generator G is also capable of syn- thesizing (noisy) sentence-attribute pairs ( ˆ x, c) which can be used to augment training data for semi-supervised learn- ing. To alleviate the issue of noisy data and ensure ro- bustness of model optimization, we incorporate a minimum entropy regularization term ( Grandvalet et al., 2004;Reed et al., 2014). The resulting objective is thus:We have derived our model and its learning procedure. The generator is first initialized by training the base VAE on a large corpus of unlabeled sentences, through the objective of minimizing Eq.(4) with the latent code c at this time sampled from the prior distribution p(c). The full model is then trained by alternating the optimization of the generator and the discriminator, as summarized in Algorithm 1.whereis the empirical Shannon entropy of distribution q D evaluated on the generated sentencê x; and β is the balancing parameter. Intuitively, the minimum entropy regularization encourages the model to have high confidence in predicting labels.The joint training objective of the discriminator using both labeled examples and synthesized samples is then given as:Our model can be viewed as combining the VAE frame- work with an extended wake-sleep method, as illustrated in Figure 2. Specifically, in Eq.(10), samples are produced by the generator and used as targets for maximum like- lihood training of the discriminator. This resembles the sleep phase of wake-sleep. Eqs.(6)-(7) further leverage the generated samples to improve the generator. We can see the above together as an extended sleep procedure based on "dream" samples obtained by ancestral sampling from the generative network. On the other hand, Eq.(4) samples c from the discriminator distribution q D (c|x) on observa- tion x, to form a target for training the generator, which corresponds to the wake phase. The effective combination enables discrete latent code, holistic discriminator metrics, and efficient mutual bootstrapping.Training of the discriminators need supervised data to im- pose designated semantics. Discriminators for different at- tributes can be trained independently on separate labeled sets. That is, the model does not require a sentence to be where λ u is the balancing parameter.annotated with all attributes, but instead needs only inde- pendent labeled data for each individual attribute. More- over, as the labeled data are used only for learning attribute semantics instead of direct sentence generation, we are al- lowed to extend the data scope beyond labeled sentences to, e.g., labeled words or phrases. As shown in the experi- ments (section 4), our method is able to effectively lift the word level knowledge to sentence level and generate con- vincing sentences. Finally, with the augmented unsuper- vised training in the sleep phrase, we show a little supervi- sion is sufficient for learning structured representations.SST-full SST-small Lexicon S-VAE 0.822 0.679 0.660 Ours 0.851 0.707 0.701 Table 1. Sentiment accuracy of generated sentences. S-VAE ( Kingma et al., 2014) and our model are trained on the three sen- timent datasets and generate 30K sentences, respectively.We apply our model to generate short sentences (length ≤ 15) with controlled sentiment and tense. Quantitative ex- periments using trained classifiers as evaluators show our model gives improved generation accuracy. Disentangled representation is learned with a few labels or only word annotations. We also validate the effect of the proposed independency constraint for interpretable generation.We compile from the TimeBank (timeml.org) dataset and obtain a lexicon of 5250 words and phrases labeled with one of {"past", "present", "future"}. The lexicon mainly consists of verbs in different tenses (e.g., "was", "will be") as well as time expressions (e.g., "in the future").Note that our method requires only separate labeled copora for each attribute. And for the tense attribute only anno- tated words/phrases are used.Sentence corpus. We use a large IMDB text corpus ( Diao et al., 2014) for training the generative models. This is a collection of 350K movie reviews. We select sentences containing at most 15 words, and replace infrequent words with the token "&lt;unk&gt;". The resulting dataset contains around 1.4M sentences with the vocabulary size of 16K.The Sentiment. To control the sentiment ("positive" or "neg- ative") of generated sentences, we test on the following la- beled sentiment data: (1) Stanford Sentiment Treebank-2 (SST-full) (Socher et al., 2013) consists of 6920/872/1821 movie review sentences with binary sentiment annotations in the train/dev/test sets, respectively. We use the 2837 training examples with sentence length ≤ 15, and evalu- ate classification accuracy on the original test set. (2) SST- small. To study the size of labeled data required in the semi-supervised learning for accurate attribute control, we sample a small subset from SST-full, containing only 250 labeled sentences for training. (3) Lexicon. We also in- vestigate the effectiveness of our model in terms of using word-level labels for sentence-level control. The lexicon from ( Wilson et al., 2005) contains 2700 words with senti- ment labels. We use the lexicon for training by treating the words as sentences, and evaluate on the SST-full test set. (4) IMDB. We collect a dataset from the IMDB corpus by randomly selecting positive and negative movie reviews. The dataset has 5K/1K/10K sentences in train/dev/test.We quantitatively measure sentence attribute control by evaluating the accuracy of generating designated sentiment, and the effect of using samples for training classifiers.We compare with semi-supervised VAE (S-VAE) ( Kingma et al., 2014), one of the few existing deep models capable of conditional text generation. S-VAE learns to reconstruct observed sentences given attribute code, and no discrimi- nators are used. See §2 and 3.1 for more discussions.Tense. The second attribute is the tense of the main verb in a sentence. Though no corpus with sentence tense an- notations is readily available, our method is able to learn from only labeled words and generate desired sentences.We use a state-of-the-art sentiment classifier ( Hu et al., 2016a) which achieves 90% accuracy on the SST test set, to automatically evaluate the sentiment generation accuracy. Specifically, we generate sentences given sentiment code c, and use the pre-trained sentiment classifier to assign senti- ment labels to the generated sentences. The accuracy is calculated as the percentage of the predictions that match the sentiment code c. Table 1 shows the results on 30K sentences by the two models which are trained with SST- full, SST-small, and Lexicon, respectively. We see that our method consistently outperforms S-VAE on all datasets. In particular, trained with only 250 labeled examples in SST- small, our model achieves reasonable generation accuracy, demonstrating the ability of learning disentangled repre- SST-full SST-small Lexicon IMDB 0.60 Figure 3. Test-set accuracy of classifiers trained on four sentiment datasets augmented with different methods (see text for details). The first three datasets use the SST-full test set for evaluation.sentations with very little supervision. More importantly, given only word-level annotations in Lexicon, our model successfully transfers the knowledge to sentence level and generates desired sentiments reasonably well. Compared to our method that drives learning by directly assessing gen- erated sentences, S-VAE attempts to capture sentiment se- mantics only by reconstructing labeled words, which is less efficient and gives inferior performance. Table 2 compares the samples generated by models with and without the constraint term, respectively. In the left column where the constraint applies, each pair of sen- tences, conditioned on different sentiment codes, are highly relevant in terms of, e.g., subject, tone, and wording which are not explicitly modeled in the structured code c while in- stead implicitly encoded in the unstructured code z. Vary- ing the sentiment code precisely changes the sentiment of the sentences (and paraphrases slightly to ensure fluency), while keeping other aspects unchanged. In contrast, the results in the right column, where the independency con- straint is unactivated, show that varying the sentiment code not only changes the polarity of samples, but can also change other aspects unexpected to control, making the generation results less interpretable and predictable.We next use the generated samples to augment the sen- timent datasets and train sentiment classifiers. While not aiming to build best-performing classifiers on these datasets, the classification accuracy serves as an auxiliary measure of the sentence generation quality. That is, higher- quality sentences with more accurate sentiment attribute can predictably help yield stronger sentiment classifiers. Figure 3 shows the accuracy of classifiers trained on the four datasets with different augmentations. "Std" is a Con- vNet trained on the standard original datasets, with the same network structure as with the sentiment discriminator in our model. "H-reg" additionally imposes the minimum entropy regularization on the generated sentences. "Ours" incorporates the minimum entropy regularization and the sentiment attribute code c of the generated sentences, as in Eq.(10). S-VAE uses the same protocol as our method to augment with the data generated by the S-VAE model. Comparison in Figure 3 shows that our method consistently gives the best performance on four datasets. For instance, on Lexicon, our approach achieves 0.733 accuracy, com- pared to 0.701 of "Std". The improvement of "H-Reg" over "Std" shows positive effect of the minimum entropy regularization on generated sentences. Further incorporat- ing the conditioned sentiment code of the generated sam- ples, as in "Ours" and "S-VAE", provides additional perfor- mance gains, indicating the advantages of conditional gen- eration for automatic creation of labeled data. Consistent with the above experiment, our model outperforms S-VAE.We demonstrate the power of learned disentangled repre- sentation by varying one attribute variable at a time. Table 3 shows the generation results. We see that each attribute variable in our model successfully controls its correspond- ing attribute, and is disentangled with other attribute code. The right column of the table shows meaningful variation of sentence tense as the tense code varies. Note that the semantic of tense is learned only from a lexicon without complete sentence examples. Our model successfully cap- tures the key ingredients (e.g., verb "was" for past tense and "will be" for future tense) and combines with the knowl- edge of well-formed sentences to generate realistic samples with specified tense attributes. Table 4 further shows gen- erated sentences with varying code z in different settings of structured attribute factors. We obtain samples that are diverse in content while consistent in sentiment and tense.We also occasionally observed failure cases as in Table 5, such as implausible sentences, unexpected variations of irrelevant attributes, and inaccurate attribute generations. Improved modeling is expected such as using dilated con- volutions as decoder, and decoding with beam search, etc. Better systematic quantitative evaluations are also desired.We have proposed a deep generative model that learns in- terpretable latent representations and generates sentences with specified attributes. We obtained meaningful genera- tion with restricted sentence length, and improved accuracy on sentiment and tense attributes. In the future we would like to improve the modeling and training as above, and extend to generate longer sentences/paragraphs and control more attributes with fine-grained structures.Our approach combines VAEs with attribute discrim- inators and imposes explicit independency constraints on attribute controls, enabling disentangled latent code. Semi-supervised learning within the joint VAE/wake-sleepWe study the interpretability of generation and the explicit independency constraint (Eq.7) for disentangled control. i highly recommend this film to anyone who appreciates music . Table 2. Samples from models with or without independency constraint on attribute control (i.e., Eq.7). Each pair of sentences are generated with sentiment code set to "negative" and "positive", respectively, while fixing the unstructured code z. The SST-full dataset is used for learning the sentiment representation.Varying the code of tense i thought the movie was too bland and too much this was one of the outstanding thrillers of the last decade i guess the movie is too bland and too much this is one of the outstanding thrillers of the all time i guess the film will have been too bland this will be one of the great thrillers of the all time Table 3. Each triple of sentences is generated by varying the tense code while fixing the sentiment code and z.Varying the unstructured code z ("negative", "past") ("positive", "past") the acting was also kind of hit or miss .his acting was impeccable i wish i 'd never seen it this was spectacular , i saw it in theaters twice by the end i was so lost i just did n't care anymore it was a lot of fun ("negative", "present") ("positive", "present") the movie is very close to the show in plot and characters this is one of the better dance films the era seems impossibly distant i 've always been a big fan of the smart dialogue . i think by the end of the film , it has confused itself i recommend you go see this, especially if you hurt ("negative", "future") ("positive", "future") i wo n't watch the movie i hope he 'll make more movies in the future and that would be devastating ! i will definitely be buying this on dvd i wo n't get into the story because there really is n't one you will be thinking about it afterwards, i promise you Table 4. Samples by varying the unstructured code z given sentiment ("positive"/"negative") and tense ("past"/"present"/"future") code.Failure cases the plot is not so original it does n't get any better the other dance movies the plot weaves us into &lt;unk&gt; it does n't reach them , but the stories look he is a horrible actor 's most part i just think so he 's a better actor than a standup i just think ! Though we have focused on the generation capacity of our model, the proposed collaborative semi-supervised learn- ing framework also helps improve the discriminators by generating labeled samples for data augmentation (e.g., see Figure 3). More generally, for any discriminative task, we can build a conditional generative model to synthesize ad- ditional labeled data. The accurate attribute generation of our approach can offer larger performance gains compared to previous generative methods.Hinton, Geoffrey E, Dayan, Peter, Frey, Brendan J, and Neal, Radford M. The "wake-sleep" algorithm for un- supervised neural networks. Science, 268(5214):1158, 1995.Hu, Zhiting, Ma, Xuezhe, Liu, Zhengzhong, Hovy, Eduard, and Xing, Eric. Harnessing deep neural networks with logic rules. In ACL, 2016a.Hu, Zhiting, Yang, Zichao, Salakhutdinov, Ruslan, and Xing, Eric P. Deep neural networks with massive learned knowledge. In EMNLP, 2016b.
