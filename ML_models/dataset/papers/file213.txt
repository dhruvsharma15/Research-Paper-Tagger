In traditional machine learning, the output consists of a single scalar, whereas in structured prediction, the out- put can be arbitrarily structured. These models have proven useful in tasks where output interactions play an important role. Examples are image segmentation, part- of-speech tagging, and optical character recognition, where taking into account contextual cues and predicting all out- put variables at once is beneficial. A widely used frame- work is the conditional random field (CRF), which mod- els the statistical conditional dependencies between input and output variables, as well as between output variables mutually. However, many tasks only require 'most-likely' predictions, which led to the rise of nonprobabilistic ap- proaches. Rather than optimizing the Bayes' risk, these models minimize a structured loss, allowing the optimiza- tion of performance indicators directly [1]. One such model is the structural support vector machine (SSVM) [2] in which a generalization of the hinge loss to multiclass and multilabel prediction is used.A downside to traditional SSVM training is the bifur- cated training approach in which unary factors (dependen- cies of outputs on inputs), and interaction factors (mutual output dependencies) are trained sequentially. A unary classification model is optimized, while the interactions are trained post-hoc. However, this two-phase approach is suboptimal, because the errors made during the train- ing of the interaction factors cannot be accounted for dur- ing training of the unary classifier. Another limitation is that SSVM factors are linear feature combinations, re- stricting the SSVM's generalization power. We propose to extend these linearities to highly nonlinear functions by means of multilayer neural networks, to which we refer as neural factors. Towards this goal, subgradient descent is extended by combining loss-augmented inference with back-propagation of the SSVM objective error into both unary and interaction neural factors. This leads to bet- ter generalization and more synergy between both SSVM factor types, resulting in more accurate and coherent pre- dictions.Our model is empirically validated by means of the com- plex structured prediction task of image segmentation on the MSRC-21, KITTI, and SIFT Flow benchmarks. The results demonstrate that integrated inference and learn- ing, and/or using neural factors, improves prediction ac- curacy over conventional SSVM training methods, such as N -slack cutting plane and subgradient descent optimiza- tion [1]. Furthermore, we demonstrate that our model is able to perform on par with current state-of-the-art seg- mentation models on the MSRC-21 benchmark.Although the combination of neural networks and struc- tured or probabilistic graphical models dates back to the early '90s [3,4], interest in this topic is resurging. Several recent works introduce nonlinear unary factors/potentials into structured models. For the task of image segmenta- tion, Chen et al. [5] train a convolutional neural network as a unary classifier, followed by the training of a dense random field over the input pixels. Similarly, Farabet et al. [6] combine the output maps of a convolutional network with a CRF for image segmentation, while Li and Zemel [7] propose semisupervised maxmargin learning with non- linear unary potentials. Contrary to these works, we trade the bifurcated training approach for integrated inference and training of unary and interactions factors. Several works [8,9,10,11] focus on linear-chain graphs, using an independently trained deep learning model whose output serves as unary input features. Contrary to these works, we focus on more general graphs. Other works suggest kernels towards nonlinear SSVMs [12,13]; we approach nonlinearity by representing SSVM factors by arbitrarily deep neural networks.Do andArtì eres [14] propose a CRF in which poten- tials are represented by multilayer networks. The perfor- mance of their linear-chain probabilistic model is demon- strated by optical character and speech recognition using two-hidden-layer neural network outputs as unary poten- tials. Furthermore, joint inference and learning in linear- chain models is also proposed by Peng et al. [15], however, the application to more general graphs remains an open problem [16]. Contrary to these works, we popose a non- probabilistic approach for general graphs by also model- ing nonlinear interaction factors. More recently, Schwing and Urtasun [17] train a convolutional network as a unary classifier jointly with a fully-connected CRF for the task of image segmentation, similar to [18,19]. Chen et al. [20] advocate a joint learning and reasoning approach, in which a structured model is probabilistically trained using loopy belief propagation for the task of optical character recog- nition and image tagging. Other related work includes Domke [21] who uses relaxations for combined message- passing and learning.Other related work aiming to improve conventional SSVMs are the works of Wang et al. [22] and Lin et al. [23], in which a hierarchical part-based model is proposed for multiclass object recognition and shape detection, focus- ing on model reconfigurability through compositional al- ternatives in And-Or graphs. Liang et al. [24] propose the use of convolutional neural networks to model an end-to- end relation between input images and structured outputs in active template regression. Xu et al. [25] propose the learning of a structured model with multilayer deformable parts for action understanding, while Lu et al. [26] propose a hierarchical structured model for action segmentation.Many of these works use probabilistic models that max- imize the negative log-likelihood, such as [14,15]. In contrast, this paper takes a nonprobabilistic approach, wherein an SSVM is optimized via subgradient descent. The algorithm is altered to back-propagate SSVM loss er- rors, based on the ground truth and a loss-augmented pre- diction into the factors. Moreover, all factors are nonlinear functions, allowing the learning of complex patterns that originate from interaction features.In this section, essential SSVM background is in- troduced, after which integrated inference and back- propagation is explained for nonlinear unary factors. Fi- nally, this notion is generalized into an SSVM model using only neural factors which are optimized by an alteration of subgradient descent.Traditional classification models are based on a predic- tion function f : X → R that outputs a scalar. In contrast, structured prediction models define a prediction function f : X → Y, whose output can be arbitrarily structured. In this paper, this structure is represented by a vector in Y = L n , with L ⊂ N a set of class labels. Structured models employ a compatibility function g : X × Y → R, parametrized by w ∈ R D . Prediction is done by solving the following maximization problem:y∈Y This is called inference, i.e., obtaining the most-likely assignment of labels, which is similar to maximum-a- posteriori (MAP) inference in probabilistic models. Be- cause of the combinatorial complexity of the output space Y, the maximization problem in Eq. (1) is NP-hard [20]. Hence, it is important to impose on g some kind of regular- ity that can be exploited for inference. This can be done by ensuring that g corresponds to a nonprobabilistic factor graph, for which efficient inference techniques exist [1]. In general, g is linearly parametrized as a product of a weight vector w and a joint feature function ϕ : X × Y → R D . Commonly, g decomposes as a sum of unary and inter- action factors. The func- tions ϕ U and ϕ I are then sums over all individual joint input-output features of the nodes ψ i (y, x) and interac- tions ψ ij (y, x) of the corresponding factor graph [1,12]. For example in the use case of Section 4, nodes are im- age regions, while interactions are connections between regions, each with their own joint feature vector. Data samples (x, y) are conform this graphical structure, i.e., x is composed of unary features x U and interaction features x I . Moreover, the unary and interaction parameters are generally concatenated as w = [(w U ), (w I ) ] . In this formulation, the unary features are defined as n , y n ; w) = max y∈Y [∆(y n , y) − g(x n , y n ; w) + g(x n , y; w)], (7)while the interaction features for 2nd-order (edges) inter- actions are defined as define a continuous and convex upper bound for the actual structured risk in Eq. (4) that can be minimized effectively by solving arg min w∈R D L(w) through numerical optimiza- tion [1,27].with i (x) the unary features corresponding to node i and ξ ij (x) the interaction features corresponding to interaction (edge) (i, j). Similarly, higher-order interaction features can be incorporated by extending this matrix into higher- order combinations of nodes, according to the interactions.In the experiments of this paper, unary features are bag- of-words features corresponding to each superpixel. Inter- action features are also bag-of-words, but this time corre- sponding to all connected superpixels.In an SSVM the compatibility function is linearly parametrized as g(x, y; w) = ϕ(x, y) and optimized effectively by minimizing an empirical estimate of the reg- ularized structured risk ); R a regularization function; λ the inverse of the regularization strength; for a set of N training samples {(x n , y n )} n∈{1,...,N } ⊂ X × Y that can be decomposed into V n nodes and E n interactions. In this paper, we make use of L 2 -regularization, hence R(w) =Traditional SSVM training methods optimize a joint parameter vector of the unary and interaction factors. However, they restrict these parameters to linear com- binations of input features, or allow limited nonlinear- ity through the addition of kernels. The objective func- tion in case of arbitrary nonlinear factors is often hard to optimize, as many numerical optimization methods re- quire a convex objective function formulation. For exam- ple, N -slack cutting plane training requires the conversion of the max-operation in Eq. (7) to a set of N |Y| linear constraints for its quadratic programming procedure [29]; block-coordinate Frank-Wolfe SSVM optimization [30] as- sumes linear input dependencies; the structured percep- tron similarly assumes linear parametrization [31]; and dual coordinate descent focuses on solving the dual of the linear L 2 -loss in SSVMs [32].Subgradient descent minimization, as described in [1,33], is a flexible tool for optimizing Eq. (6) as it naturally allows error back-propagation. This algorithm alternates between two steps. First,2 . Furthermore, in line with our image segmentation use case in Section 4, the loss function is the class-weighted Hamming distance between two label assignments, oris calculated for all N training samples, which is called the loss-augmented inference or prediction step, derived from Eq. (7). In this paper, general inference for deter- mining Eq. (1) is approximated via the α-expansion [34] algorithm, whose effectiveness has been validated through extensive experiments [35]. Loss-augmented prediction as in Eq. (8) is incorporated into this procedure by adding the loss term η(y n n i )[y with [·] the Iverson brackets and V n the number of nodes (i.e., inputs to the unary factors, which corresponds to the number of nodes in the underlying factor graph) in the n-th training sample. Contrary to maximum likelihood approaches [14,20,19], the Hamming distance allows us to directly maximize performance metrics regarding accu- racy. By setting η(y i = y i ] to the unary factors. Second, these z-values are used to calculate a subgradi- ent 2 of Eq. (6) as Due to the piecewise nature of the loss function ∆, tra- ditional gradient-based optimization techniques are inef- fective for solving Eq. (4). However, according to Zhang [27], the equations, in order to update w. Traditional SSVMs assume that g(x, y; w) = ϕ(x, y) in which ϕ is a prede- fined joint input-output feature function. Commonly, this joint function is made up of the outputs of a nonlinear 'unary' classifier C : [36]. This classifier is trained upfront, based on the different unary inputs corresponding to each node in the underlying factor graph. Due to the linear definition of g, the SSVM model is learning linear combi- nations of these classifier outputs as its unary factors. InAlgorithm 1: Integrated SSVM subgradient descent with neural unary and linear interaction factors Input: # iterations T ; learning rate curve µ/(t 0 + t); inverse regularization strength λ; training samplesInitialize w to 0 and θ according to [28]; the output layer weights are initialized to 0.general, the interaction factors are not trained through a separate classifier, and are thus linear combinations of the interaction features directly. We propose to replace the pretraining of a nonlinear unary classifier, and the transformation of its outputs through linear factors, by the direct optimization of non- linear unary factors. In particular, the unary part of g is represented by a sum f of outputs of an adapted neural network which models factor values. To achieve this, the loss-augmented prediction step defined in Eq. (8) is altered to augmented prediction z n . In case n , y n ; w) = 0, we set ∇ θ L = θ. This gradient incorporates the loss-augmented prediction of Eq. (9) and is back-propagated through the underlying network to adjust each element of θ. The al- tered subgradient descent method is shown in Algorithm 1. Herein, L n represents the objective function for the n-th training sample, i.e., L n (θ, w) =In contrast to gradient descent, subgradient methods [1,33] do not guarantee the lowering of the objective func- tion value in each step. Therefore, the current best value L (t) * = min{L )} is memorized in each iteration t, along with the corresponding parameter values (w * , θ * ). As such, the objective value L * decreases at each step asThis update rule is omitted from Algorithm 1 to improve readability.∂L ∂w , originally defined as the subderivative of the objective function in Eq. (6), remains unaltered. However, we can no longer assume that ∂L ∂θ conforms to the definition of a subgradient due to its nonconvexity. However, we can calculaten∈N with N the set of indices corresponding to training samples for which n , y n ; w) &gt; 0 in Eq. (7), for a particular loss- Because the loss terms in Eq. (7) are no longer affine in- put transformations due to the introduced nonlinearities of the neural network, we can no longer assume Eq. (6) to be convex, as is the case for conventional SSVMs. Al- though theoretical guarantees can be made for the conver- gence of (sub)gradient methods for convex functions [37], and particular classes of nonconvex functions [38], no such guarantees can be made for arbitrary nonconvex functions [39]. The problem of optimizing highly nonconvex func- tions is studied extensively in neural network gradient de- scent literature. However, it has been demonstrated that nonconvex objectives can be minimized effectively due to the high dimensionality of the neural network parameter space [40]. Dauphin et al. [41] show that saddle points are Algorithm 2: Integrated SSVM subgradient descent with both unary and interaction neural factors Input: # iterations T ; learning rate; inverse regularization strength λ; training set {(x n , y n )} Output: optimized parameters θ ∈ R K and γ ∈ R M 1 Initialize θ and γ according to [28]; the weights of the output layers are initialized to 0.13 end much likelier than local minima in multilayer neural net- work objective landscapes. In particular, the ratio of sad- dle points to local minima increases exponentially with the parameter dimensionality. Several methods exists to avoid these these saddle points, e.g., momentum [42]. Further- more, Dauphin et al. [41] show, based on random matrix theory, that the existing local minima are very close to the global minimum of the objective function. This can be un- derstood intuitively as the probability that all directions surrounding a local minimum lead upwards is very small, making local minima not an issue in general. The empir- ical results presented in Section 4.2 reinforce this believe by demonstrating that the regularized objective function can still be minimized effectively, as we achieve accurate predictions.As described in Algorithm 1, the (sub)gradient is defined over whole data samples, which each consist of multiple nodes. f thus models the unary part of the compatibility function g, which is a sum of the V n unary factors. There- fore, the function f (x, y; θ) decomposes as a sum of neural unary factorsIn this section we extend the notion of nonlinear fac- tors beyond the integration of the training of a unary classifier. We now also replace the linear interaction part ϕ I (x, y) of the compatibility function g with a func- tion h(x, y; γ) that decomposes as a sum of neural inter- action factorsi=1 with x I the interaction features in x, N i (y) the combi- nation of node labels in the i-th interaction, and E n the number of interactions in the n-th training sample. The functioni=1 with x U the unary features in x. The nonlinear function f * : X → R |L| is a multiclass multilayer neural network parametrized by θ ∈ R K , whose inputs are features cor- responding to the V n different nodes. It forms a template for the neural unary factors. In this network f * (x Q is parametrized by γ ∈ R M , and forms a template for the interaction factors. Herein, Q depends on the interaction order, e.g., Q = 2 in the Section 4 use case as connections between nodes are then edges. Interaction factors are generally not trained up- front. However, neural interaction factors are useful as they can extract complexer interaction patterns, and thus transcend the limited generalization power of linear com- binations. In image segmentation for example, interaction features consisting of vertical gradients and a 90• -angle can indicate that the two connected nodes belong to the same class. The loss-augmented inference step in Eq. (9) is now adapted toU y∈Y i ; θ), the softmax-function is removed from the output layer, such that it matches the unary factor range R |L| . The argu- ment y of the joint feature function is used as an index y i to select a particular output unit. while the compatibility function becomes g(x, y; θ, γ) = f (x, y; θ) + h(x, y; γ). The two distinct models f and h are trained in a similar fashion to the method described in Algorithm 1, as depicted in Algorithm 2. Notice that this method can easily be adjusted for batch or online learning by adapting and moving the weight updates at line 12 into the inner loop.Like the unary function f * in Eq. (11), h * (x I i ; γ) is a multiclass multilayer neural network in which the top softmax-function is removed, shared among all E n inter- action factors. The output layer dimension matches the number of interaction label combinations, |L| Q in the most general case. For example in image segmentation, for a problem with symmetric edge features, the number of out- put units in h * is 1 2 |L|(|L|+1), which all represent different states for a particular interaction factor (in this case the interactions are undirected edges, thus N i (y) consists of the i-th edge's incident nodes).The resulting structured predictor no longer requires two-phase training in which linear interaction factors are combined with the upfront training of a unary classifier, whose output is transformed linearly into unary factor val- ues. It makes use of highly nonlinear functions for all SSVM factors, by way of multilayer neural networks, us- ing an integration of loss-augmented inference and back- propagation in a subgradient descent framework. This al- lows the factors to generalize strongly while being able to mutually adapt to each other's parameter updates, leading to more accurate predictions.is repeated for a larger dataset, namely the SIFT Flow benchmark [48], consisting of 33 classes with 2488 train- ing and 200 testing images.All image pixels are clustered into ±300 regions using the SLIC [49] superpixel algorithm. For each region, gra- dient (DAISY [50]) and color (in HSV-space) features are densely extracted. These features are transformed two times into separate bags-of-words via minibatch k-means clustering (once 60 gradient and 30 color words, once 10 and 5 words). The unary input vectors form (60 + 30)-D concatenations of the first two bags-of-words. The model's connectivity structure links together all neighboring re- gions via edges. The edge/interaction input vectors are based on concatenations of the second set of bags-of-words. Both (10+5)-D input vectors of the edge's incident regions are concatenated into a (2 × (10 + 5))-D vector. Moreover, two edge-specific features are added, namely the distance and angle between adjacent superpixel centers, leading to (2 × (10 + 5) + 2)-D interaction feature vectors.Factors are trained with (regular) momentum, using a learning rate curve µIn this section, our model is analyzed on the task of image segmentation. Herein, the goal is to label different image regions with a correct class label. This is cast into a structured prediction problem by predicting all image re- gion class labels simultaneously. There is one unary factor in underlying SSVM graphical structure for every image region, while interactions represent edges between neigh- boring regions. First, our model is analyzed and its dif- ferent variants are compared to conventional SSVM train- ing schemes. Second, the best performing variant is com- pared with state-of-the-art segmentation approaches. Our model is implemented as an extension of PyStruct [43], using Theano [44] for GPU-accelerated neural factor opti- mization. t0+t , with µ and t 0 parameters, and t the current training iteration number as used in Algo- rithms 1 and 2. The regularization, learning rate, and mo- mentum hyperparameter values are tuned using a valida- tion set by means of a coarse-and fine-grained grid search over the parameter spaces, yielding separate settings for the unary and pairwise factors. The linear parameters w are initialized to 0, while the neural factor parameters θ and γ are initialized according to [28], except for the top layer weights which are set to 0. The class weights η(y nThe model analysis experiments are executed on the widely-used MSRC-21 benchmark [45], which consists of 276 training, 59 validation, and 256 testing images. This benchmark is sufficiently complex with its 21 classes and noisy labels, and focuses on object delineation as well as irregular background recognition. Furthermore, the exper- iments are executed on the KITTI benchmark [46] con- sisting of 100 training and 46 testing images, augmented with 49 training images of Kundu et al. [47]. This lat- ter benchmark consists of 11 classes, but we drop the 3 least frequently-occurring ones as they are insufficiently represented in the dataset. Finally, the same experiment i ) in Eq. (5) are set to correct for class imbalance. The model is trained using CPU-parallelized loss-augmented prediction, while the neural factors are trained using GPU parallelism.The following models are compared: unary-only (unary), N -slack cutting plane training (CP) with delayed constraint generation, subgradient descent (SGD) 3 , inte- grated training with neural unary and linear interaction factors (int+lin), bifurcated training with neural interac- tion factors (bif+nrl), and integrated training with neural unary and neural interaction factors (int+nrl).Multiclass logistic regression is used as unary classifier, trained with gradient descent by cross-entropy optimiza- tion. All unary neural factors contain a single hidden layer with 256 tanh-units, for direct comparison of integrated learning with upfront logistic regression training. The in- teraction neural factors contain a single hidden layer of 512 tanh-units to elucidate the benefit of nonlinear fac- tors, without overly increasing the model's capacity. The experiment is set up to highlight the benefit of integrated learning by restricting the unary factors to features insuffi- ciently discriminative on their own. This deliberately leads to noisy unary classification, forcing the model to rely on contextual relations for accurate prediction. The interac- tion factors encode information about their incident region    feature vectors to allow neural factors to extract mean- ingful patterns from gradient/color combinations. We de- liberately encoded less information in the interaction fea- tures, such that the model cannot solely rely on interaction factors for accurate and coherent predictions.Accuracy results on the MSRC-21 [45] test images are presented in Table 1, while Figure 1 shows a handful of illustrative examples that compare segmentations attained by SGD with int+nrl. The results of the same experiment for the KITTI benchmark [46], augmented with additional training images Kundu et al. [47], are shown in Table 2 and Figure 2. Qualitative results on the SIFT Flow [48] dataset are shown in Figure 3, while accuracy results are shown in Table 3.The results show that unary-only prediction is very inac- curate (pixel-wise/class-mean accuracy of 36.3/23.1% for the MSRC-21 dataset, 53.8/42.8% for the KITTI dataset, and 44.7/7.5% for the SIFT Flow dataset). The reason for this is that unary features are not sufficiently dis- tinctive to allow for differentiation between classes due to their low dimensionality. Accurate predictions are only possible by taking into account contextual output relations, demonstrated by the increased accuracy of CP (MSRC-21: 59.4/48.5%; KITTI: 61.5/46.7%; SIFT Flow: 62.5/13.8%) as well as SGD (MSRC-21: 59.2/49.6%; KITTI: 65.5/50.6%; SIFT Flow: 65.9/15.3%). These structured predictors learn linear relations between image regions, which allows them to correct errors originating from the underlying unary classifier. However, the unary factor's linear weights w have only limited capability for error correction in the opposite direction, due to the fact that the SSVM cannot alter the unary classifier parame- ters post-hoc.Using an integrated training approach such as int+lin, in which the SSVM is trained end-to-end, improves accu- racy (MSRC-21: 67.4/58.5%; KITTI: 70.2/57.8%; SIFT Flow: 70.2/15.6%) over the bifurcated procedures CP and SGD. Although neither the unary or interaction fea- tures are very distinctive, the integrated procedure up- Figure 4: Visualization of the synergy between unary and interaction factors. In bifurcated training the interactions make unary factors redundant as these cannot be adapt to errors made by the interactions. In integrated training, combining both factor types leads to a higher accuracy as they can mutually adapt to each other's weight updates.  78 77 91 68 88 87 76 73 77 93 97 73 57 95 81 76 81 46 56  respectively. This increase can be attributed to the higher number of param- eters, as well as the added nonlinearities in combination with correct regularization. The model has greater gener- alization power, allowing the factors to extract more com- plex and meaningful interaction patterns. Neural factors offer great flexibility as they can be stacked to arbitrary depths. This leads to even higher generalization, as indi- cated by the increased accuracy (MSRC-21: 71.6/65.1%; KITTI: 77.6/63.6%; SIFT Flow: 71.5/17.2%) of the deeper 3-layer (int+nrl) model. Herein both unary and interac- tion factors are 3-hidden-layer neural networks consisting of 256 and 512 units (rectified linear units for MSRC- 21 and KITTI and tanh units for SIFT Flow) in each layer respectively. Our model can thus easily be extended, for example by letting neural factors represent the fully- connected layer in convolutional neural networks. As such, it serves as a foundation for more complex structured mod- els.All methods converge within 600 epochs, with one epoch taking approximately 12.62 seconds for the MSRC-21 dataset, 4.35 seconds for the KITTI dataset, and 197.27 seconds on the SIFT Flow dataset for the int+nrl algo- rithm. Since the implementation of our algorithm is not optimized for speed, these values can be further reduced by better exploitation of CPU parallelism. Figure 4 illustrates the synergy between unary and in- teraction factors achieved through both integrated and bifurcated training, exercised on the MSRC-21 dataset. The bars depict model test accuracy when using only unary or pairwise factors, by setting either the pairwise or unary factors respectively to a zero factor value, thus ϕ I (x, y) or ϕ U (x, y) = 0 ∀y ∈ Y. Although the unary factors alone perform well in bifurcated training, nearly all accuracy can be attributed to the interactions. A possible explanation is that both types essentially learn the same information. The interactions correct errors of the underlying classifier and ultimately make unary fac- tors redundant. In integrated training, neither the unary or interaction factors alone attain a high accuracy, but the combination of both does.We explain this synergistic relationship with an exam- ple: Unary factors assign to a region of class A, a second- to-highest factor value to class A, a highest value to class B, and a low value to class C. The interactions also as- sign a second-to-highest value to class A, but a highest value to class C, and a low value to class B. Independently both factors incorrectly predict the region of class A as belonging to class B or class C. However, when combined they correctly assign a highest value to class A. In the figure, bifurcated training only shows limited signs of fac- tor synergy, as the optimization procedure is insufficiently able to steer unary and pairwise parameters in different di- rections, which causes them have a similar discriminative focus. This observation leads us to believe that integrated learning and inference results in higher accuracy by syner- gistic unary/interaction factor optimization. Both factor types are no longer optimized for independent accuracy, but mutually adapt to each other's parameter updates, which results in enhanced predictive power.In addition to the previous experiments, the viability of our neural factor model is shown through comparison with the closely related work of Liu et al. [51] on the MSRC-21 dataset. Liu et al. make use of features ex- tracted from square regions of varying size around each superpixel, through means of a pretrained convolutional neural network. We compare our model with theirs by using overfeat features [58] in a similar fashion, trained on individual regions. Furthermore, the model settings have been altered with respect to the previous experi- ments. More specifically, 1,000 SLIC superpixels are uti- lized for the over-segmentation preprocessing step, enforc- ing superpixel connectivity and merging any superpixel with a surface area below a particular threshold. DAISY gradient and HSV color features are extracted according to a regular lattice, and clustered via minibatch k-means clustering. Next, the same type of features are extracted for each individual pixel, leading to unary and pairwise factor feature vectors. Moreover, the (x, y)-position of the superpixel (median-based) center is included in the unary feature vectors, while the distance and angle between the two superpixel centers is encoded into the interaction fea- ture vectors. The neural factors are represented by multi- layer neural networks using tanh-units, trained according to our Algorithm 2, using conventional momentum and single image-sized batches per gradient update. Classes are balanced by weighing them with the inverse of the class frequency. The results are presented in Table 4, which indicate that our model is capable of performing on par with the current state-of-practice, when used in conjunc- tion with more advanced methods, e.g., overfeat features. Moreover, similar to Liu et al. [51], we have compared our model with other less closely related methods for complete- ness, for which the results are shown below the horizontal line in Table 4.A structured prediction model that integrates back- propagation and loss-augmented inference into subgradi- ent descent training of structural support vector machines (SSVMs) is proposed. This model departs from the tra- ditional bifurcated approach in which a unary classifier is trained independently from the structured predictor. Fur- thermore, the SSVM factors are extended to neural fac- tors, which allows both unary and interaction factors to be highly nonlinear functions of input features. Results on a complex image segmentation task show that end-to- end SSVM training, and/or using neural factors, leads to more accurate predictions than conventional subgradient descent and N -slack cutting plane training. Results show that our model serves as a foundation for more advanced structured models, e.g., by using latent variables, learned feature representations, or complexer connectivity struc- tures.
