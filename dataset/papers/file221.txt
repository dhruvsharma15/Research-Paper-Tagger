Some decisions are easier to make than others-for exam- ple, large, unoccluded objects are easier to recognize. Ad- ditionally, different difficult decisions may require different expertise-an avid birder may know very little about iden- tifying cars. We hypothesize that complex decision-making tasks like visual classification can be meaningfully divided into specialized subtasks, and that a system designed to perform a complex task should first attempt to identify the subtask being presented to it, then use that information to select the most suitable algorithm for its solution. For a given data rep- resentation, some regions of the input space may be classified con- fidently, while other regions may be ambiguous.This approach-dynamically routing signals through an in- ference system, based on their content-has already been incorporated into machine vision pipelines via methods such as boosting ( Viola et al., 2005), coarse-to-fine cas- cades ( Zhou et al., 2013), and random decision forests (Ho, 1995). Dynamic routing is also performed in the primate visual system: spatial information is processed somewhat separately from object identity information (Goodale &amp; With this in mind, we propose a mechanism for introducing cascaded evaluation to arbitrary feedforward ANNs, focus- ing on the task of object recognition as a proof of concept. Instead of classifying images only at the final layer, every layer in the network may attempt to classify images in low- ambiguity regions of its input space, passing ambiguous images forward to subsequent layers for further considera- tion (see Fig. 1 for an illustration). We propose three ap- proaches to training these networks, test them on small im- age datasets synthesized from MNIST ( LeCun et al., 1998) and CIFAR-10 ( Krizhevsky &amp; Hinton, 2009), and quantify the accuracy/efficiency trade-off that occurs when the net- work parameters are tuned to yield more aggressive early classification policies. Additionally, we propose and evalu- ate methods for appropriating regularization and optimiza- tion techniques developed for statically-routed networks. Since the late 1980s, researchers have combined ar- tificial neural networks with decision trees in various ways (Utgoff, 1989)  (Sirat &amp; Nadal, 1990). More re- cently, Kontschieder et al. (2015) performed joint opti- mization of ANN and decision tree parameters, and Bulo &amp; Kontschieder (2014) used randomized multi-layer net- works to compute decision tree split functions.To our knowledge, the family of inference systems we dis- cuss was first described by Denoyer &amp; Gallinari (2014). Additionally, Bengio et al. (2015) explored dynamically skipping layers in neural networks, and Ioannou et al. (2016) explored dynamic routing in networks with equal- length paths. Some recently-developed visual detection systems perform cascaded evaluation of convolutional neu- ral network layers ( Li et al., 2015;Cai et al., 2015;Girshick, 2015;Ren et al., 2015); though highly specialized for the task of visual detection, these modifications can rad- ically improve efficiency.Source Sink 1 Source Sink 1 Figure 2. A 2-way junction, j. dj is an integer function of the source features. When dj = 0, the signal is propagated through the top sink, and the bottom sink is inactive. When dj = 1, the signal is propagated through the bottom sink, and the top sink is inactive.an animal, or the prevalence of occlusion in the scene).While these approaches lend evidence that dynamic routing can be effective, they either ignore the cost of computation, or do not represent it explicitly, and instead use opaque heuristics to trade accuracy for efficiency. We build on this foundation by deriving training procedures from arbitrary application-provided costs of error and computation, com- paring one actor-style and two critic-style strategies, and considering regularization and optimization in the context of dynamically-routed networks.To address this, instead of computing a 2-dimensional ar- ray of local features at each layer, we compute a pyramid of features (resembling the pyramids described by Ke et al. (2016)), with local descriptors at the bottom and global de- scriptors at the top. At every junction j, the score vector s j is computed by a small routing network operating on the last-computed global descriptor. Our multipath architec- ture is illustrated in Fig. 3.For a given input, network ν, and set of routing decisions d, we define the cost of performing inference:In a statically-routed, feedforward artificial neural network, every layer transforms a single input feature vector into a single output feature vector. The output feature vector is then used as the input to the following layer (which we'll refer to as the current layer's sink), if it exists, or as the ouptut of the network as a whole, if it does not.We consider networks in which layers may have more than one sink. In such a network, for every n-way junction j a signal reaches, the network must make a decision, d j ∈ {0..n}, such that the signal will propagate through the i th sink if and only if d j = i (this is illustrated in Fig.  2). We compute d j as the argmax of the score vector s j , a learned function of the last feature vector computed before reaching j. We'll refer to this rule for generating d from s as the inference routing policy.where c err (ν, d) is the cost of the inference errors made by the network, and c cpt (ν, d) is the cost of computation. In our experiments, unless stated otherwise, c err is the cross- entropy loss andwhere n ops (ν, d) is the number of multiply-accumulate operations performed and k cpt is a scalar hyperparame- ter. This definition assumes a time-or energy-constrained system-every operation consumes roughly the same amount of time and energy, so every operation is equally expensive. c cpt may be defined differently under other con- straints (e.g. memory bandwidth).Convolutional network layers compute collections of local descriptions of the input signal. It is unreasonable to expect that this kind of feature vector can explicitly encode the global information relevant to deciding how to route the entire signal (e.g., in the case of object recognition, whether the image was taken indoors, whether the image containsWe propose three approaches to training dynamically- routed networks, along with complementary approaches to regularization and optimization, and a method for adapting to changes in the cost of computation.  Since d is discrete, c inf (ν, d) cannot be minimized via gradient-based methods. However, if d is replaced by a stochastic approximation, ˆ d, during training, we can engi- neer the gradient of E[c inf (ν, ˆ d)] to be nonzero. We can then learn the routing parameters and classification parameters simultaneously by minimizing the loss where J is the set of junctions encountered when making the routing decisionsˆddecisionsˆ decisionsˆd, and c ure is the utility regression er- ror cost, defined:whereIn our experiments, the training routing policy samplesˆdsamplesˆ samplesˆd such that j = −c inf (ν k ure is a scalar hyperparameter, and νwhere τ is the network "temperature": a scalar hyperpa- rameter that decays over the course of training, converging the training routing policy towards the inference routing policy.j is the subnetwork consisting of the i th child of ν j , and all of its descendants. Since we want to learn the policy indirectly (via cost pre- diction), ˆ d is treated as constant with respect to optimiza- tion.Alternatively, we can attempt to learn to predict the ex- pected utility of making every routing decision. In this case, we minimize the loss To improve the stability of the loss and potentially accel- erate training, we can adjust the routing utility function u such that, for every junction j, u j is independent of the routing parameters downstream of j. Instead of predict- ing the cost of making routing decisions given the current downstream routing policy, we can predict the cost of mak- ing routing decisions given the optimal downstream routing policy. In this optimistic variant of the critic method,Many regularization techniques involve adding a model- complexity term, c mod , to the loss function to influence learning, effectively imposing soft constraints upon the net- work parameters (Hoerl &amp; Kennard, 1970;Rudin et al., 1992;Tibshirani, 1996). However, if such a term af- fects layers in a way that is independent of the amount of signal routed through them, it will either underconstrain frequently-used layers or overconstrain infrequently-used layers. To support both frequently-and infrequently-used layers, we regularize subnetworks as they are activated byˆd byˆ byˆd, instead of regularizing the entire network directly.quent layers based onˆdonˆ onˆd. With this policy, at every training interation, mini-batch stochastic gradient descent shifts the parameters associated with layer by a vector δ * , defined:i where λ is the global learning rate and g i is the gradient of the loss with respect to the parameters in for training example i, under d * . Analogously, the scaled parameter adjustment underˆdunderˆ underˆd can be written For example, to apply L2 regularization to critic networks, we define c mod :i where pis the probability with whichˆdwhichˆ whichˆd routes example i through w∈W We want to select α such that where W is the set of weights associated with the layers activated byˆdbyˆ byˆd, and k L2 is a scalar hyperparameter.For actor networks, we apply an extra term to control the magnitude of s, and therefore the extent to which the net explores subpotimal paths:Substituting the definitions of δ andw∈W j∈J jSince every g i where k dec is a scalar hyperparameter indicating the relative cost of decisiveness.is sampled independently, we can rewrite this equation: 2 c mod is added to the loss function in all of our experiments. Within c mod , unless stated otherwise, ˆ d is treated as con- stant with respect to optimization.where n ex is the number of training examples in the mini- batch and v is the elementwise variance of g i, for any i (since every example is sampled via the same mechanism). We can now show that Both training techniques attempt to minimize the expected cost of performing inference with the network, over the training routing policy. With this setup, if we use a constant learning rate for every layer in the network, then layers through which the policy routes examples more frequently will receive larger parameter updates, since they contribute more to the expected cost.So, for every layer we can scale the learning rate by −1 , and the variance of the weight updates will be sim- ilar thoughout the network. We use this technique, unless otherwise specified, in all of our experiments.To allow every layer to learn as quickly as possible, we scale the learning rate of each layer dynamically, by a factor α , such that the elementwise variance of the loss gradient with respect to parameters is independent of the amount of probability density routed through it.To derive α , we consider an alternative routing policy, d * , that routes all signals though then routes through subse- We may want a single network to perform well in situations with various degrees of computational resource scarcity (e.g. computation may be more expensive when a device battery is low). To make the network's routing behavior re- sponsive to a dynamic c cpt , we can concatenate c cpt 's known parameters-in our case, {k cpt }-to the input of every rout- ing subnetwork, to allow them to modulate the routing pol- icy. To match the scale of the image features and facili- tate optimization, we express k cpt in units of cost per ten- million operations.In all of our experiments, we use a mini-batch size, n ex , of 128, and run 80,000 training iterations. We per- form stochastic gradient descent with initial learning rate 0.1/n ex and momentum 0.9. The learning rate decays con- tinuously with a half-life of 10,000 iterations. networks to classify images from a small-image dataset synthesized from MNIST ( LeCun et al., 1998) and CIFAR- 10 ( Krizhevsky &amp; Hinton, 2009) (see Fig. 4). Our dataset includes the classes "0", "1", "2", "3", and "4" from MNIST and "airplane", "automobile", "deer", "horse", and "frog" from CIFAR-10 (see Fig. 4). The images from MNIST are resized to match the scale of images from CIFAR-10 (32×32), via linear interpolation, and are color- modulated to make them more difficult to trivially dis- tinguish from CIFAR-10 images (MNIST is a grayscale dataset).The weights of the final layers of routing networks are zero-initialized, and we initialize all other weights using the Xavier initialization method (Glorot &amp; Bengio, 2010). All biases are zero-initialized. We perform batch normal- ization (Ioffe &amp; Szegedy, 2015) before every rectification operation, with an of 1×10 −6 , and an exponential moving average decay constant of 0.9.τ is initialized to 1.0 for actor networks and 0.1 for critic networks, and decays with a half-life of 10,000 iterations. k dec = 0.01, k ure = 0.001, and k L2 = 1 × 10 −4 . We se- lected these values (for τ , k dec , k ure , and k L2 ) by exploring the hyperparameter space logarithmically, by powers of 10, training and evaluating on the hybrid MNIST/CIFAR-10 dataset (described in section 5.1). At a coarse level, these values are locally optimal-multiplying or dividing any of them by 10 will not improve performance.We augment our data using an approach that is popu- lar for use with CIFAR-10 ( Lin et al., 2013) (Srivastava et al., 2015) (Clevert et al., 2015. We augment each im- age by applying vertical and horizontal shifts sampled uni- formly from the range [-4px,4px], and, if the image is from CIFAR-10, flipping it horizontally with probability 0.5. We fill blank pixels introduced by shifts with the mean color of the image (after gamma-decoding). Figure 4. Sample images from the hybrid MNIST/CIFAR-10 dataset. We recolor images from MNIST via the following pro- cedure: we select two random colors at least 0.3 units away from each other in RGB space; we then map black pixels to the first color, map white pixels to the second color, and linearly interpo- late in between.We compare approaches to dynamic routing by train- ing 153 networks to classify small images, varying the policy-learning strategy, regularization strategy, optimiza- tion strategy, architecture, cost of computation, and details of the task. The results of these experiments are reported in Fig. 5-10. Our code is available on GitHub.To compare routing strategies in the context of a simple dataset with a high degree of difficulty variation, we train For a given computational budget, dynamically-routed net- works achieve higher accuracy rates than architecture- matched statically-routed baselines (networks composed of the first n columns of the architecture illustrated in Fig.  3, for n ∈ {1..8}). Additionally, dynamically-routed net- works tend to avoid routing data along deep paths at the beginning of training (see Fig. 8). This is possibly be- cause the error surfaces of deeper networks are more com- plicated, or because deeper paths are less stable-changing the parameters in any component layer to better classify images routed along other, overlapping paths may decrease performance. Whatever the mechanism, this tendency to initially find simpler solutions seems to prevent some of the overfitting that occurs with 7-and 8-layer statically-routed networks.  Compared to other dynamically-routed networks, opti- mistic critic networks perform poorly, possibly because op- timal routers are a poor approximation for our small, low- capacity router networks. Actor networks perform better than critic networks, possibly because critic networks are forced to learn a potentially-intractable auxilliary task (i.e. it's easier to decide who to call to fix your printer than it is to predict exactly how quickly and effectively every- one you know would fix it). Actor networks also consis- tently achieve higher peak accuracy rates than comparable statically-routed networks, across experiments.the cross-entropy error in the c ure term with the classifica- tion error. Although these networks do not perform as well as the original pragmatic critic networks, they still outper- form comparable statically-routed networks.Based on our experiments with the hybrid dataset, regular- izingˆdizingˆ izingˆd, as described in section 4.4, discourages networks from routing data along deep paths, reducing peak accu- racy. Additionally, some mechanism for encouraging ex- ploration (in our case, a nonzero k dec ) appears to be neces- sary to train effective actor networks.Throughput-adjusting the learning rates (TALR), as de- scribed in section 4.5, improves the hybrid dataset perfor- mance of both actor and critic networks in computational- resource-abundant, high-accuracy contexts. For a given computational budget, architectures with both 2-and 3-way junctions have a higher capacity than sub- trees with only 2-way junctions. On the hybrid dataset, un- der tight computational constraints, we find that trees with higher degrees of branching achieve higher accuracy rates. Unconstrained, however, they are prone to overfitting. In dynamically-routed networks, early classification layers tend to have high accuracy rates, pushing difficult decisions downstream. Even without energy contraints, terminal lay- ers specialize in detecting instances of certain classes of images. These classes are usually related (they either all come from MNIST or all come from CIFAR-10.) In net- works with both 2-and 3-way junctions, branches special- ize to an even greater extent. (See Fig. 6  Although actor networks may be more performant, critic networks are more flexible. Since critic networks don't re- quire E[c inf (ν, ˆ d)] to be a differentiable function ofˆdofˆ ofˆd, they can be trained by samplingˆdsamplingˆ samplingˆd, saving memory, and they support a wider selection of training routing policies (e.g. and c inf definitions. In addition to training the standard critic networks, we train networks using a variant of the pragmatic critic training policy, in which we replace We train a single actor network to classify images from the hybrid datset under various levels of computational con- straints, using the approach described in section 4.6, sam- pling k cpt randomly from the set mentioned in Fig. 5 for each training example. This network performs comparably to a collection of 8 actor nets trained with various static values of k cpt , over a significant, central region of the accu- racy/efficiency curve, with an 8-fold reduction in memory consumption and training time.To probe the effect of the inference task's difficulty dis- tribution on the performance of dynamically-routed net-works, we train networks to classify images from CIFAR- 10, adjusting the classification task to vary the frequency of difficult decisions (see Fig. 9). We call these vari- ants CIFAR-2-labelling images as "horse" or "other"- and CIFAR-5-labelling images as "cat", "dog", "deer", "horse", or "other". In this experiment, we compare actor networks (the best-performing networks from the first set of experiments) to architecture-matched statically-routed networks.To test whether dynamic routing is advantageous in higher- capacity settings, we train actor networks and architecture- matched statically-routed networks to classify images from CIFAR-10, varying the width of the networks (see Fig.  10). Increasing the model capacity either increases or does not affect the relative advantage of dynamically-routed net- works, suggesting that our approach is applicable to more complicated tasks. Our experiments suggest that dynamically-routed networks trained under mild computational constraints can oper- ate 2-3 times more efficiently than comparable statically- routed networks, without sacrificing performance. Addi- tionally, despite their higher capacity, dynamically-routed networks may be less prone to overfitting.When designing a multipath architecture, we suggest sup- porting early decision-making wherever possible, since cheap, simple routing networks seem to work well. In con- volutional architectures, pyramidal layers appear to be rea- sonable sites for branching. Statically-Routed Nets Actor NetsThe actor strategy described in section 4.1 is generally an effective way to learn a routing policy. However, the prag- matic critic strategy described in section 4.2 may be better suited for very large networks (trained via decision sam- pling to conserve memory) or networks designed for appli- cations with nonsmooth cost-of-inference functions-e.g. one in which k cpt has units errors/operation. Adjusting learning rates to compensate for throughput variations, as described in section 4.5, may improve the performance of deep networks. If the cost of computation is dynamic, a single network, trained with the procedure described in sec- tion 5.5, may still be sufficient. While we test our approach on tasks with some degree of difficulty variation, it is possible that dynamic routing is even more advantageous when performing more complex tasks. For example, video annotation may require special- ized modules to recognize locations, objects, faces, human actions, and other scene components or attributes, but hav- ing every module constantly operating may be extremely inefficient. A dynamic routing policy could fuse these modules, allowing them to share common components, and activate specialized components as necessary.We find that dynamic routing is more beneficial when the task involves many low-difficulty decisions, allowing the network to route more data along shorter paths. While dy- namic routing offers only a slight advantage on CIFAR-10, dynamically-routed networks achieve a higher peak accu- racy rate on CIFAR-2 than statically-routed networks, at a third of the computational cost.Another interesting topic for future research is growing and shrinking dynamically-routed networks during train- ing. With such a network, it is not necessary to specify an architecture. The network will instead take shape over the course of training, as computational contraints, mem- ory contraints, and the data dictate.
