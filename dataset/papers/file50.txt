Sentiment analysis is the automated detection of emotions and attitudes towards a particular subject, event or entity, and has received an increasing amount of interest since the year 2000 [1], [2]. Sentiment analysis has been applied to many problem domains; for instance, determining sentiments of consumers towards products, or mining social media to gain an understanding of the public's opinion on matters such as corruption [1]- [3].In this study, we propose a novel evolutionary algorithm (EA) which is tasked with compressing text, whereby the objective is to retain the correct sentiment classification of the compressed text. To achieve this, the EA makes use of POS (Parts of Speech) to determine which POS can be removed from the text without hindering the classification performance. EAs [4], [5] -inspired by nature -make use of a population of individuals which are evolved over several iterations to solve optimisation problems.To illustrate the idea, consider the sentence "I went home yesterday, opened the door and was immediately faced with a terrible shock". The key sentiment-encoding phrase is "terrible shock". We thus want to propose an algorithm that can learn to evolve rules that can effectively do this compression. The remaining words in the sentence do not contain any useful information in determining the sentiment expressed, and thus the rules can discard those words.Feng et al. [6] proposed a Chinese text compression method with the objective of preserving the opinions expressed in the text to retain the sentiment, and to ensure that the compressed sentence is grammatically correct. The authors propose a score function which takes into consideration three primary functions; namely a word significance, a linguistic and an opinion scoring function. The word significance function makes use of the word frequency properties to allocate a score to each word. The scores were obtained by processing a corpus containing 30,000 documents. The linguistic score was obtained using a n-gram probabilistic function which made use of Google search results. The opinion score made use of an opinion lexicon to allocate a value to each word based on the frequency of the word. The authors created the lexicon from three different sources and the resulting lexicon contained 32,051 words for which the sentiment (positive, neutral or negative) was known. A dynamic programming algorithm was used in order to determine how many words should be present in a compressed sentence by evaluating several candidate compressed sentences. The score function was applied to each candidate sentence and the result was divided by the number of words in the compressed sentence. The compressed sentence with the highest value after this operator was deemed to be the final compressed sentence for a given uncompressed sentence. One Chinese data set of compressed sentences was manually created to evaluate their proposed approach. The study revealed that their proposed approach was able to outperform a traditional sentence compression method when the sentences were evaluated -in terms of the opinion and grammar -by a human.Che et al. [7] also proposed a text compression method for sentiment analysis. In their study, they make use of 10 features (which are determined for every word) to perform the compression. The features are grouped into basic, sentiment related, semantic and syntactic features. The basic features include the words before and after the word for which the features are being constructed for; they also include the POS tags for those words. There are two sentiment features, namely a binary field denoting if the word is a perception word and if it is a polarity word. These words were obtained from an existing lexicon. The semantic features include prefix and suffix characters and also Brown word features which helps identify that words which are written differently represent the same thing. They also include word embedding which makes use of Word2Vec [8] to determine if two words have a similar meaning. The syntactic feature makes use of a single feature which indicates the relationship between the words in the sentence. The sentence compression is conducted prior to the sentiment analysis.With the limited amount of existing work in this field, we propose and investigate PARSEC (PARts-of-Speech for sEn- timent Compression), which makes use of an EA to achieve text compression with minimal loss in sentiment accuracy.POS, in languages, are defined as the primary groups of words that are grammatically similar. Common POS include, but are not limited to: adjective, verb and noun. For example, the words "dog", "house" and "student" are examples of nouns.In this study, the Stanford Log-linear Part-Of-Speech Tagger [9] was used to convert the original data sets into their corresponding POS tags. Thus, each word in a dataset was converted into a POS tag, and the length of each sentence in the original dataset was identical to that of the POS tagged dataset. For example, if the following sentence was found in the original dataset: "this is a great product", it would be converted into "DT VBZ DT JJ NN" (which corresponds to the POS equivalent) in the POS tagged dataset.We used the Penn Treebank tag set [10], [11]. This set contains 36 tags and an additional 12 tags to denote certain characters such as comma, semi-colon and other characters.This study proposes a new type of individual for EAs - referred to as a compressor -which reduces the length of sentences when applied to a dataset. The compressor is made up of several rules, and in turn, each rule is made up of a sequence of POS tags and a decision. The decision is applied whenever it's sequence of POS tags matches the POS tags in the data. The decisions represent the indices of the words which will be removed in the matched sequence. Figure 1 illustrates an example of a compressor. the equivalent POS dataset. Furthermore, let X i,j denote sentence i and word j in X, and Y i,j denote sentence i and word j in Y .The compressor in the figure has 10 rules denoted as R 1 , R 2 , R 3 , ..., R 10 . The first rule, R 1 , has 2 tags which are represented by the sequence "JJ, NN". This rule has one decision, and that is, to delete the word at index 0. This implies that when this particular compressor is applied, rule R 1 will find POS tags in Y corresponding to the sequence "JJ NN". Let Y l,m and Y l,m+1 denote two consecutive words in Y which have the sequence "JJ NN". The decision in R 1 is to delete index 0, thus R 1 will delete Y l,m and consequently it will delete X l,m . Thus, the size of X and Y has been reduced by one. Each time R 1 finds the exact sequence "JJ NN", the POS tag and word corresponding to "JJ" (index 0) in Y and X are deleted.Similarly for R 10 , Let Y l,m , Y l,m+1 and Y l,m+2 denote three consecutive words in Y which have the sequence "NN VB RB". The decision in R 10 is to delete index 0 and 2, thus R 10 will delete Y l,m , Y l,m+2 , X l,m and X l,m+2 from Y and X respectively for each occurrence of the POS tags "NN VB RB".When a rule is being processed, if a punctuation mark occurs, then the rule evaluation immediately stops. This mech- anism was incorporated so that the sequence of tags -which is encapsulated by a rule -is applied to a single sentence and is not applied across two separate sentences. For example, consider the two following sentences "This book was really funny. Great, tomorrow is Friday." which corresponds to: "DT NN VBD RB JJ. JJ, NN VBZ NNP." Assume that some rule has the following tags "JJ JJ" and the decision is to delete both indices. If the punctuation marks are not taken into consideration, then the rule will match with the words "funny" and "great". This will result in "This book was really . , tomorrow is Friday." Consequently, the sentiments in these two sentences are no longer positive. However, if punctuation is taken into consideration, then the rule will not delete any words since the full stop separates the two sentences.In this study, we define the term 'wildcard', which repre- sents the notion of 'any POS' tag and is denoted with a '*' symbol. Thus, when a rule is being evaluated, the wildcard POS can match with any POS in the POS dataset. For example, if a rule has the following tags: "JJ * NNP", then any POS sequence that has 'JJ', followed by any POS, followed by 'NNP' will cause the rule to match with that POS sequence.Algorithm 1 presents the generalized pseudocode to match the tags in a rule with the POS tags in the POS dataset. The algorithm also presents how to delete words from the original and POS dataset once a rule matches with a sequence. In the following explanation, let X denote some original dataset for which PARSEC is being applied to, and let Y denoteThe pseudocode for creating an initial population of com- pressors is presented in algorithm 2. Several individuals are created based on a predefined user parameter, namely the population size. Several rules have to be created for each compressor. There must be at least one rule, and a user-defined Algorithm 1: Pseudocode to apply a compressor to a sentence and compress the text.input: compressor the compressor to evaluate input: original sentence the original sentence input: POS sentence the POS sentence input: length sentence the length of the sentence to evaluate 1 begin Algorithm 2: Pseudocode to create the initial population of compressors.input: population size the number of compressors to create 1 begin 2 for i ← 0 to population size do Create the tags using algorithm 3 and add the rules to new rule.Create the decisions using algorithm 4 and add the rules to new rule.18 return The initial population.parameter, namely max rules , is implemented to restrict the total number of rules. When creating the rules, the algorithm iterates until it has reached max rules , and a probability value of 0.5 was set to determine if a rule was to be created or not, as can be seen on line 9 in algorithm 2. Each rule consists of two primary parts, namely the tags and the decisions, the pseudocode for the creation of those respective parts are presented in algorithms 3 and 4. The pseudocode for the fitness evaluation of a compressor is presented in algorithm 6. Each instance in the dataset is considered in turn. The sentiment for each instance in the original dataset is computed using algorithm 5. When a compressor is evaluated, it is applied to each instance and a compressed sentence is created. The sentiment of each compressed sentence is computed using algorithm 5. The compressed sentiment is then compared to the original sentiment. If these are the same then the compressed sentence has had no effect on the sentiment when compared to the original. Conversely, if the values are different, then there are two possibilities. Either the compressed sentiment is equal to the correct sentiment as labelled in the training data (in which case the compressor is rewarded) or it is not (in which case the compressor is penalised). Thus, the fitness function takes input : sentence the sentence to be evaluated input : dictionary the dictionary of sentiment words input : negation words the list of negation words output: The sentiment for the evaluated sentence 1 begin Algorithm 6: Pseudocode to compute fitness of a com- pressor.input : compressor the compressor to evaluated input : sentence a list of sentences for which compressor will be evaluated on input : original lengths a list of lengths for each sentence in the original data set input : original sentiments a list of sententiment values determined by applying algorithm 5 on the original data set inputcompressed sentiment ← apply algorithm 5. into consideration the number of new instances for which the compressor produces the correct result. A multi-objective fitness function was created to combine the fitness, the average reduction in terms of the length of the sentences before and after compression, and the size of the compressor in terms of the number of rules. Thus, the objective was to maximize the fitness and average reduction in sentences, and to minimize the size of the compressor.Twelve data sets were created by randomly selecting reviews from corresponding Amazon review datasets [12]. For each created data set, 1000 positive and 1000 negative reviews were randomly selected from the larger corresponding Amazon data set. The larger Amazon data sets were obtained from [12], [13]. The data sets were: Amazon Instant Video (AIV), Apps for Android, Automotive, Baby, Beauty, Digital Music, Health and Personal Care, Musical Instruments (MI), Patio Lawn and Garden, Pet Supplies, Tools and Home Improvement, and Toys and Games.We propose a set of experiments whereby the compression rate is a user parameter and PARSEC must generate com- pressors that can compress the original datasets to reach the specified compression rate.To achieve this, a lower and upper user-defined compression bound were defined. The lower compression bound (LCB) was implemented to ensure that the compressors did not result in a compression ratio less than the specified value. Similarly, the upper compression bound (UCB) ensured that the compressors did not result in a compression ratio greater than the specified value. Thus, every compressor in the EA population had to have a compression rate between the LCB and UCB.Furthermore, two additional user-defined parameters were implemented to ensure that the total number of rules within each compressor remained within a certain bound. The two parameters were named compressionRules min and compression rates of 10% and 15% respectively. When exper- imenting with PARSEC we posed the following question. For a predetermined drop in accuracy, how much compression is achievable by PARSEC? For a threshold of -1% compression, Vivek and LingPipe were able to achieve up to 30% compres- sion. For this same threshold five methods could achieve up to 20% compression rate. Regardless of the compression rate used, both Stanford and Sentiment140 did not obtain any result less than -1%. These two algorithms produced the weakest performance with PARSEC. compressionRules max . The compressionRules max param- eter prevents compressors from having an extremely large number of rules. Both parameters aid in restricting the search space in terms of the number of rules to create and maintain for each compressor during the evolutionary process. The initial population generation had to respect the LCB and UCB, and respect the minimum and maximum number of rules. The mutation operator also had to respect these constraints. Several sentiment analysis algorithms were applied to the original and compressed datasets to determine the difference in accuracy and to investigate the performance of PARSEC. The following algorithms were used: SentiStrength [14], [15], MeaningCloud [16], Vivek [17], Stanford [18], uClassify [19], Sentiment140 [20], Intellexer [21] and LingPipe [22]. We first applied the sentiment analysis algorithms described in section IV-B to the original datasets and record the test accuracy. Then, we ran PARSEC using the baseline evalua- tion to create compressor rules. Once the compressors were created, we applied the compressors to the original datasets to generate the compressed data. We applied the sentiment analysis algorithms on the compressed data and recorded the test accuracy. In the following section we report on the change in accuracy between the compressed and original data. PARSEC evolved a population of 250 compressors over 100 generations, the crossover rate was 60% and mutation rate was 40%. V. RESULTS AND CONCLUSION Figure 2 shows the average change in test accuracy across the different methods based on the compression rates. The general trend is a decrease in performance with the largest decrease in performance observed by Sentiment140. LingPipe and SentiStrength were the only two methods that achieved a positive change in performance (on certain datasets) on For a threshold of -2%, five algorithms could achieve up to 30% compression rate and LingPipe was able to achieve up to 50% compression. When the threshold is set to -3% four methods could achieve up to 50% compression.We additionally wanted to determine the change in test accuracy when a much larger compression rate was used. Table  II presents the results when a compression rate of 75% was used. Only certain algorithms were tested due to our limited access to the sentiment analysis algorithms. These results reveal that a large compression rate is achievable without a great loss in test accuracy: LingPipe obtained a loss of -3.3% accuracy.An example of PARSEC compression is as follows. The original sentence (which contains 56 words and is already stemmed): "this be a wonderful movie involve fascinating people who be such great actor and actress. the event be interesting and I never get tire of watch the episode. I be so sad to see that they be not go to keep go with the life of all these inhabitant of Lark rise and candleford. Mrs. Hamlin". The compressed sentence (22 words): "this be wonderful movie involve fascinating people who actress. get tire. so sad to see not keep go rise candleford. Mrs. Hamlin".It would be of interest to incorporate the PARSEC algo- rithm directly into a sentiment analysis algorithm instead of via a simple dictionary approach. One could achieve this by replacing the fitness function used in the evolutionary phase with a more sophisticated sentiment analysis algorithm. This would allow the emergence of an algorithm where the compression and sentiment analysis are mutually optimised for best performance. The financial assistance of the National Research Foun- dation (NRF) towards this research is hereby acknowledged. Opinions expressed and conclusions arrived at, are those of the authors and are not necessarily to be attributed to the NRF.Change Below are four rules which were randomly selected from a PARSEC model to illustrate some of the evolved rules. This model had a total of 38 rules. The POS tags are presented in order of appearance between square brackets. The indices start from zero. Rule 1 denotes that if the POS "NNP" is followed by "JJ", then delete both words. Rule 4 denotes that if "IN" is followed by any POS and then followed by "VB", then delete the word at index 1. Decisions: [1] This study empirically demonstrates that machine learning can reduce the amount of data needed to determine the sentiments within sentences with little loss in accuracy. To achieve this, we proposed an evolutionary algorithm, PARSEC, which evolves a population of chromosomes which encode rules for compression based on the removal of POS.We studied the test accuracies achieved by the eight algo- rithms when set compression rate thresholds were enforced. Two algorithms showed marginal improvements in accuracy on several data sets for a compression rate of 15%. Addi- tionally, there were 9 data sets whereby some of the algo- rithms were able to yield an improvement in accuracy for a compression rate of 30%. At a threshold of -1% sentiment accuracy loss, two methods were able to achieve up to 30% compression, five methods up to 20% compression, and six methods up to 10% compression. The best performing algo- rithm, LingPipe, showed only modest losses in accuracy even at high compression: 3.3% for a four-fold data compression. Tables III to VIII present the difference in test accuracy re- sults for the various compression rates. The various sentiment analysis algorithms are abbreviated as follows: IN, LP, MC, S140, SS, ST, uC and V refer to Intellexer, LingPipe, Meaining- Cloud, Sentiment140, SentiStrength, Stanford, uClassify and Vivek respectively. For a compression rate of 10%, the best and worst change in accuracy were obtained by LingPipe and Sentiment140 respectively. Based on all the findings for 10 per cent compression, there were 21 cases across all the methods and data sets whereby the change in accuracy was greater than zero. For a compression rate of 15% the number of cases was 17 whereby LingPipe obtained the best average change in accuracy with a value of 0.0%.The best change in accuracy for 20% compression rate was obtained by uClassify with a value of 0.7 on two data sets. There were six data sets for which uClassify reduced the data up to 20% and for which the test accuracy on the compressed data was better than on the original data. Additionally, there were 14 cases in total across all the algorithms whereby the change in accuracy was greater than zero for 20% compres- sion.The findings revealed that a for the compression rate of 25% there were 14 cases for which the change was greater than zero, and the best change in average accuracy was obtained once again by LingPipe with a value of -0.3%. There was a reduction performance in terms of the number of cases having a change greater than zero when a compression of 30% was used; notably 9 cases. uClassify however, on 5 datasets, had a test accuracy greater than zero. Finally, only two algorithms were able to obtain improvements in terms of the changes for a compression rate of 50%, namely uClassify and LingPipe, with changes in 3 and 2 data sets respectively.  Apps for Android    
