One of the main obstacles in studying the human mind is the problem of representation.How is information represented in the brain, and how does the representation change depending on the type and nature of the information? This has long been an intriguing and challenging question in the history of science across many disciplines.Recently, advances in pattern recognition and neuroscience have provided researchers access to neural data that reflects brain activity during deployment of cognitive processes, enabling a whole new range of complementary methods and approaches to study the human mind ( Norman et al., 2006;Polyn et al., 2005; Wang et al., 2003;Haynes and Rees, 2006;Mitchell et al., 2004; Van De Ville and Lee, 2011). Multi-voxel pattern analysis (MVPA) has enabled researchers to infer the degree to which a type of information or a cognitive process is represented in the brain at a given time, based on distributed patterns of neural activation.An important step for MVPA is to extract relevant features acquired from neuroimaging methods, such as functional magnetic resonance imaging (fMRI). The feature space enables representation of the type of information at a given stage during cognitive processing. Once the raw data is preprocessed, a common approach has been feeding the feature vector formed by the voxel intensity values to one of the well-known classifiers or clustering algorithms, such as Kernel Machines, Neural Networks, Bayesian classifiers or Ensemble Classifiers.In order to find a powerful representation of the fMRI measurements several noise reduction and feature extraction approaches have been reported in the literature. For instance, a widely used approach for representation of fMRI data is to identify and select the active voxels for the condition of interests. A group of methods to select the informative voxels employs Independent Component Analysis (ICA) and Principal Component Analysis (PCA). Both approaches capture the spatial and temporal dependencies in fMRI measurements (Lautrup, Hansen, Law, Morch, Svarer &amp; Strother, 1995;Rasmussen, Abrahamsen, Madsen &amp; Hansen, 2012). Another approach is to identify active voxels for the experimental conditions against a control-baseline condition using the General Linear Model (GLM) (e.g. Pereira, Mitchell &amp; Botvinick, 2009). This approach can further be improved via employing an information mapping technique called Searchlight (Kriegeskorte, Goebel, Bandettini (2006), which combines the signals from a voxel and its immediately adjacent neighbors to identify informative regions. Accordingly, Information Mapping can detect how well the multivariate signal in a local region can differentiate between experimental conditions. In the current study, we suggest a new complementary approach, called Mesh Learning for pattern analysis of neuroimaging data. In this approach, neural activity corresponding to a particular type of information/cognitive state is represented as a collection of meshes. The arc weights of these meshes describe the interconnections among the voxels and can be estimated from patterns of activation acquired via functional Magnetic Resonance Imaging (fMRI). This approach is similar to Searchlight in that it considers the signal from a voxel and its neighbors.In Searchlight, informative voxels are found based on the combination of signals across all voxels in a specific region for appropriate feature selection. In the Mesh Learning model, however, the relationship between the neural activity of the neighboring voxels are modeled and directly fed to the classification algorithm. That is, rather than using this relationship for feature selection, the Mesh Model directly incorporates the information representing the relationship between the neural activation of the neighbor voxels into the classification algorithm. Figure 1. Illustration of the Mesh Learning approach. First step; we find the p-nearest neighbor of each voxel, using a spatial distance measure. Second step; we form a local mesh around each voxel, in a star topology where the surrounding voxels (green nodes) are the p- nearest neighbors of the center voxel (blue node). The mesh is defined for each voxel form the feature space of a classifier. Third step; the arc weights between the center voxel and its neighbors, in the mesh, are estimated by a linear regression model of the voxel intensity values, at a time instant (corresponding to the response of voxels to a predefined cognitive input). Fourth step; for each center voxel, a p-dimensional vector is formed with the entries of estimated arc weights. Fifth step; for each time instant, the arc weight vector for all the voxels are concatenated under a Mxp dimensional vector (MAD), where M is the number of active voxels. The steps of the Mesh Learning are shown in Figure 1. In the first step, the p-nearest neighbors of each voxel are found using a spatial distance measure. In the second step, a local mesh is formed around each voxel in star topology (see Figure 2), where the surrounding voxels (green nodes in Figure 2) are the p-nearest neighbors of the center voxel (blue node in Figure 2). In the third step, the arc weights between the center voxel intensities and its surroundings in the mesh are computed via least squares estimation. In the fourth step, for each center voxel, a p-dimensional vector is formed with the entries of estimated arc weights. Here we tested whether the proposed Mesh Learning approach can successfully predict the type of information represented in the brain during memory encoding and retrieval, using a previously established paradigm (Öztekin &amp; McElree, 2007;Öztekin, Curtis &amp; McElree;Öztekin &amp; Badre, 2011), In a previous study (Öztekin &amp; Badre, 2011), successful classification performance was obtained in predicting the semantic category of words during memory encoding and retrieval using a Neural Network classifier. In the current investigation, employing the proposed Mesh Model, we tested whether the success with which a classifier can predict the type of information represented in the brain during a cognitive operation could be improved.The results implicate that the proposed representation yields higher discriminative power compared to PCA, ICA, GLM and Searchlight methods. Accordingly, we propose that a supervised learning system such as the Mesh Learning model suggested in this study could provide a useful tool to decode brain activation during cognitive processing.One right-handed female adult (age 22) participated in the experiment. The participant had normal or corrected-to-normal vision, and was screened for use of CNS affecting drugs, for psychiatric or neurological conditions, and for contraindications for MRI.Stimuli consisted of 21 instances of 10 semantic categories from the category norms of (Van Overschelde, Rawson and Dunlosky, 2004). The experiment consisted of eight 10- minute runs. Each run contained 30 experimental trials, in which participants studied a 5-item list, solved four math problems, and made a recognition judgment to a test word.  Following the fourth math problem, participants were presented with a test word and indicated whether the word was a member of the current study list. Participants had 2000 ms to respond to the test probe. The inter-trial interval consisted of presentation of a fixation cross on the center of the screen for variable duration (ranging from 0 to 8000 ms).Critically, study lists and probes consisted of words that belonged to the same semantic category (e.g. animals) (Öztekin &amp; McElree, 2007(Öztekin &amp; McElree, , 2010Öztekin, Curtis &amp; McElree, 2009;Öztekin and Badre, 2011). A total of ten semantic categories were used in the study. This way, we were able to employ supervised learning algorithms to classify the examples from one of the semantic categories of words the participant was encoding and retrieving from memory.Whole-brain imaging was performed on a Siemens 3T Magnetom Trio MRI system.Functional images were acquired using a gradient-echo echo-planar sequence, followed by high-resolution T1-weighted (MP-RAGE) anatomical images were collected for visualization.Head motion was restricted using firm padding that surrounded the head. Visual stimuli were projected onto a screen, and viewed through a mirror attached to a standard head coil.Image processing and data analysis were performed using SPM5(http://www.fil.ion.ucl.ac.uk/spm/). Following quality assurance procedures to assess outliers or artifacts in volume and slice-to-slice variance in the global signal, functional images were corrected for differences in slice acquisition timing by resampling all slices in time to match the first slice, followed by motion correction across all runs (using sinc interpolation).Functional data were then normalized based on MNI stereotaxic space using a 12-parameter affine transformation along with a nonlinear transformation using cosine basis functions.Images were resampled into 2-mm cubic voxels and then spatially smoothed with an 8-mm FWHM isotropic Gaussian kernel. Next, the functional data were detrended to account for baseline shifts across runs, and for scanner drift across the entire session for pattern analysis.Previous research has implicated the lateral temporal cortex in storage and retrieval of semantic information (Damasio, 1990;Badre &amp; Wagner, 2002;Thompson-Schill, 2003).Accordingly, classifiers were trained to distinguish the examples from ten semantic categories used in the experiment based on the distributed activation in lateral temporal cortex. The lateral temporal cortex ROI was structurally defined, and consisted of the left middle and left inferior temporal gyri. A set of regressors, which assigned each functional scan to a particular classification condition (i.e. the specific semantic category) assuming a lagged hemodynamic response function were determined. Consistent with previous research (e.g., Polyn et al., 2005, Öztekin &amp; Badre, 2011, onsets were shifted forward by three points to account for the hemodynamic response lag, and a standard leave-one-out (N-minus-one) run-by-run cross validation approach was used for the pattern analysis. Classification success was determined by the proportion of correct category classifications across the test trials.An initial descriptive analysis on the neuroimaging data suggested that intensity measures across the ten classes might not be sufficient in providing the desired discriminative power among the ten semantic categories. This fact can be observed from Figure 4, where at each    In this study, the multiple voxel intensity values measured at a time instant denote an example which belongs to one of the ten semantic categories. The data set  Figure 2). If we increase p, then the mesh size is also increased, including more neighborhood relations. For p=0, the mesh is reduced to a single voxel, which is identical to classical MVPA representation of fMRI data. A critical problem is to find an "optimal" mesh size. A simple method to estimate the mesh size is to use one-leave-out cross validation applied to fMRI data. However, note that as p increases, the problem becomes exponentially expensive.For practical reasons, we did not seek for an optimal p-value and suffice to test the performance of the proposed method for a mesh size of 6.Next, we obtain an Nxp dimensional Mesh Arc Descriptor (MAD) vector, In the current investigation, we evaluated the proposed model using four widely available classifiers, namely, Support Vector Machines (SVM), k-Nearest Neighbor (k-NN), Naïve Bayes and Neural Networks.A block diagram which summarizes the proposed cognitive process classification methods is given in Figure 6. Experiment design, data acquisition and pre-processing, and anatomic feature selection methods are given in the previous sections. In this section, we focus on algorithms for feature selection, extraction and classification. In order to evaluate the proposed Mesh Learning model, several MVPA methods were implemented. As mentioned above, our region of interested consisted of the lateral temporal cortex (LTC). In the implementation of classification algorithms, we refer to this structurally defined ROI consisting of the entire LTC as Raw Features. In addition, classification algorithms were also employed on the features obtained from algorithmic feature selection and extraction algorithms that are further employed on the LTC ROI.We applied the proposed Mesh Learning method to our data for mesh size with p=6 to consider the nearest neighbors of each voxels that are spatially distributed in the 3D space of fMRI data. First, we extracted the MAD vectors to represent the information about the relationships between the spatially distributed voxels intensity measurements for each example. In order to further test the proposed Mesh Model, we also implemented three well- known feature extraction algorithms, namely, ICA, PCA and Kernel PCA. It is important to note the difference in approach across PCA, ICA and MAD vectors. In PCA, the voxel intensity measurements with maximal statistical variance are identified. That is, the features obtained from PCA provide distinct information about the statistics of the voxel intensity measurements. On the other hand, ICA maximizes the statistical independence between the voxel intensity measurements. Therefore, the features (or voxels) obtained from the ICA are statistically independent. MAD vectors estimated in the Mesh Model describe the linear relationship between a voxel and its neighbors.In the implementations, we used PCA-st and Kernel PCA-st implementations of Sidhu et al.( Sidhu et al., 2012) on the raw features over space and time without Fast Fourier Transform.We used Fast ICA implementation (Hyvarinen, 1999) for ICA. In each iteration, we compute the rank of the training and test data matrices as equal to the number of training and test samples, which are M tr and M te , respectively. In other words, the number of non-zero principle and independent components of PCA-st and ICA which are computed using training and test data matrices is equal to M tr and M te respectively. Therefore, the parameters of PCA-st and For the implementation of GLM, separate regressors were generated for each condition and were modeled using a canonical hemodynamic response function and its temporal derivative.Data across runs were concatenated and modeled as one session with mean signal and scanner drift entered as a covariate. Using a fixed-effects model, a voxel-wise contrast identified voxels that showed more activation for the experimental conditions against the baseline at an uncorrected threshold of p &lt; .001.For the implementation of Searchlight, we employed the Searchmight ( Pereira &amp; Botvinick, 2011). In the spatial voxel selection phase of the searchlight, we selected the voxels that reside in a neighborhood of 2x2x2 of each voxel. Then, we employed a Gaussian Naïve Bayes (GNB) classifier to measure the voxel scores considering the classification accuracies.Classification accuracies of the GNB classifiers employed by each voxel were considered as the voxel scores for feature selection, i.e. the voxels with classification accuracies equal to or greater than a threshold AccΨ acc were selected as the features, and the selected features were fed to the classifiers.To evaluate the classification performance across these methods, we employed several well-  Chang and Lin, 2011). In addition, we employed Kernel density estimation method to estimate likelihood or class conditional density, in the implementation of GNB classifier ( Duda et al., 2001).In all of the implementations, classifier parameters, including the number of nearest neighbors k of k-NN, kernel parameters of RBF Kernels of SVM and kernelized GNB were selected using leave one out cross-validation on training data. In the line search optimization of the classifier parameters, k values were considered in the interval [1, N ], where N is the number of training samples, the kernel width parameter σ is searched in the interval log( ) [ 10,5]   and the SVM cost penalization parameter c is searched in the interval log( ) [ 10,5] c  . The parameters of the NN were selected as the default learning rate and termination time parameters in the Princeton Multi-Voxel Pattern Analysis Toolbox. A leave-one-out (N-minus-one) run-by-run cross validation provided eight iterations of classification performance for each method. Figure 3 illustrates the classification results for each method across the five classifiers.An inspection of Figure 7  Notably, the classification performances for the Mesh Model also indicate that k-NN, SVM and GNB classifiers give higher performances (an average performance of 56% for k-NN, 44% for SVM Linear, 62% for SVM RBF and 46% for GNB) compared to Neural Networks (an average performance of 33%). This performance difference might result from the nature of the classification algorithms. Specifically, k-NN algorithm employs a local learning rule in which the local relational information can be successfully used for learning. Similarly, SVM methods avoid the data scarcity problems (e.g., Duda et al., 2001). Additionally, a GNB classifier, which employs kernel density estimation, provides better approximations to true class conditional densities than the non-kernelized estimates ( Duda et al., 2001).Classification performances depicted in Figure 7 also indicate that the non-linear classifiers In this paper, we proposed a new approach, namely Mesh Learning, for pattern analysis of brain activity during cognitive processing. We tested the proposed Mesh Model's performance in classifying the semantic category of information represented in the brain during encoding and retrieval from memory. The proposed method employs local meshes, defined in a It is important to note that the proposed Mesh Learning model was tested on a data set acquired in a recognition memory study, and hence the current set of results only demonstrate its success in classification of the type of information (i.e. semantic category) represented in the brain during memory encoding and retrieval operations. Future research would prove additional insight into the feasibility of the proposed model for a wider range of cognitive processes.
