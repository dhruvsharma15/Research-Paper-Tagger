Reasoning is essential to natural language processing tasks, most obviously in examples like document summarization, question-answering, and dialogue. Previous efforts in this direction are built on rule-based models, requiring first mapping natural languages to logic forms and then inference over them. The mapping (roughly corresponding to semantic parsing), and the inference, are by no means easy, given the variability and flexibility of natural language, the variety of the reasoning tasks, and the brittleness of a rule-based system.Just recently, there is some new effort, mainly represented by Memory Network and its dynamic variants [9,5], trying to build a purely neural network-based reasoning system with fully distributed semantics that can infer over multiple facts to answer simple questions, all in natural language, e.g., Fact1: John travelled to the hallway. Fact2: Mary journeyed to the bathroom. Question: Where is Mary? The Memory Nets perform fairly well on simple tasks like the examples above, but poorly on more complicated ones due to their simple and rigid way of modeling the dynamics of question-fact interaction and the complex process of reasoning.In this paper we give a more systematic treatment of the problem and propose a flexible neural reasoning system, named Neural Reasoner. It is purely neural network based and can be trained in an end-to-end way [6], using only supervision from the final answer. Our contributions are mainly two-folds• we propose a novel neural reasoning system Neural Reasoner that can infer over multiple facts in a way insensitive to 1) the number of supporting facts, 2)the form of language, and 3) the type of reasoning;• we give a particular instantiation of Neural Reasoner and a multi-task training method for effectively fitting the model with relatively small amount of data, yielding significantly better results than existing neural models on two artificial reasoning task;Neural Reasoner has a layered architecture to deal with the complicated logical relations in reasoning, as illustrated in Figure 1. It consists of one encoding layer and multiple reasoning layers. The encoder layer first converts the question and facts from natural language sentences to vectorial representations. More specifically,whereWith the representations obtained from the encoding layer, the reasoning layer recursively updates the representations of questions and facts,through the interaction between question representation and fact representations. Intuitively, this interaction models the reasoning, including examination of the facts and comparison of the facts and the questions. Finally at layer-L, the resulted question representation q (L) is fed to an answerer, which layer can be a classifier for choosing between a number of pre-determined classes (e.g., {Yes, No}) or a text generator for create a sentence. We argue that Neural Reasoner has the following desired properties:• it can handle varying number of facts, including irrelevant ones, and reach the final conclusion through repeated processing of filtering and combining;• it makes no assumption about the form of language, as long as enough training examples are given.In this section we give an instantiation of Neural Reasoner described in Section 2, as illustrated in Figure 2. In a nutshell, question and facts, as symbol sequences, are first converted to vectorial representations in the encoding layer via recurrent neural networks (RNNs). The vectorial representations are then fed to the reasoning layers, where the question and the facts get updated through an nonlinear transformation jointly controlled by deep neural networks (DNNs)and pooling. Finally at the answering layer, the resulted question representation is used to generate the final answer to the question. More specificallyK } for the global updated representation q ( through a pooling operation (see Section 3.2 for more details)• finally in Layer-L, the interaction net (DNN L ) returns only question update, which, after summarization by the pooling operation, will serve as input to the Answering Layer.In the rest of this section, we will give details of different components of the model.The encoding layer is designed to find semantic representations of question and facts. Suppose that we are given a fact or a question as word sequence {x 1 , · · · , x T }, the encoding module summarizes the word sequence with a vector with fixed length. We have different modeling choices for this purpose, e.g., CNN [4] and RNN [7], while in this paper we use GRU [2], a variant of RNN, as the encoding module. GRU is shown to be able to alleviate the gradient vanishing issue of RNN and have similar performance to the more complicated LSTM [3]. As shown in Figure 3, GRU takes as input a sequence of word vectors (for either question or facts) where |V| stands for the size of vocabulary for input sentences. Detailed forward computations are as follows:where E ∈ R m×k is the word embedding and W xz , W xr , W xh , W hz , W hr , U hh are weight matrices. We take the last hidden state h t as the representation of the word sequence. The modules in the reasoning layers include those for question-fact interaction, pooling.On reasoning layer the k th interaction is between q ( and f• Model-based: In the case of temporal-reasoning, there is crucial information in the sequential order of the facts. To account for this temporal structure, we can use a CNN or RNN to combine the information in {qAt layer-L, the query representation q (L) after the pooling will serve as the features for the final decision.For simplicity, we focus on the reasoning tasks which can be formulated as classification with predetermined classes. More specifically, we apply Neural Reasoner to deal with the following two types of questions• Type I: General questions, i.e., questions with Yes-No answer;• Type II: Special questions with a small set of candidate answers.At reasoning Layer-L, it performs pooling over the intermediate results to select important information for further uses.After reaching the last reasoning step, in this paper we take two steps, Q 2 is sent to a standard softmax layer to generate an answer which is formulated as a classification problem. There is another type of prediction as classification where the effective classes dynamically change with instances, e.g., the Single-Supporting-Fact task in [9]. Those tasks cannot be directly solved with Neural Reasoner. One simple way to circumvent this is to define the following score functionwhere g match is a function (e.g., a DNN) parameterized with θ, and w z is the embedding for class z, with z being dynamically determined for the task.The training of model tunes the parameters in {RNN 0 , DNN 1 , · · · , DNN L } and those in the softmax classifier. Similar to [6], we perform end-to-end training, taking the final answer as the only supervision. More specifically, We use the cross entropy for the cost of classificationwhere n indexes the instances in the training set T , and r n = {Q n , F n,1 , · · · , F n,Kn } stands for question and facts for the n th instance. Our end-to-end training is the same as [6], while the training in [9]and [5] use the step- by-step labels on the supporting facts for each instance (see Table 1 for examples) in addition to the answer. As described in [6], those extra labels brings much stronger supervision just the answer in the end-to-end learning setting, and typically yield significantly better result on relatively complicated tasks.We use auxiliary training to facilitate the learning of representations of question and facts. Basically, in addition to using the learned representations of question and facts in the reasoning process, we also use those representations to reconstruct the original questions or their more abstract forms with variables (elaborated later in Section 4.2).In the auxiliary training, we intend to achieve the following two goals • to compensate the lack of supervision in the learning task. In our experiments, the supervision can be fairly weak since for each instance it is merely a classification with no more than 12 classes, while the number of instances are 1K to 10K.• to introduce beneficial bias for the representation learning task. Since the network is a complicated nonlinear function, the back-propagation from the answering layer to the encoding layer can easily fail to learn well.  As illustrated in Figure 4, we take the simplest way to fuse the auxiliary tasks (recovering) with the main task (reasoning) through linearly combining their costs with trade-off parameter αwhereE reasoning is the cross entropy loss describing the discrepancy of model prediction from correct answer (see Section 3.4), and E recovering is the negative log-likelihood of the sequences (question or facts) to be recovered. More specifically,where the likelihood is estimated as in the encoder-decoder framework proposed in [2]. On top of the encoding layer (RNN), we add another decoding layer (RNN) which is trained to sequentially predict words in the original sentence.Instead of recovering the original sentence in question and facts, we also study the effect of producing a more abstract form in the auxiliary training task. More specifically, we let the decoding RNN to recover a sentence with entities replaced with variables (treated as particular symbols), e.g.,The triangle is above the pink rectangle.−−−−→x is above y. Through this, we intend to teach the system a more abstract way of representing sentences (both question and facts) and their interactions. More specifically,• all the entities are only meaningful only when they are compared with each other.In other words, the model (in the encoding and reasoning layers) should not consider specific entities, but their general notions.• it helps the model to focus on the relations between the entities, the commonality of different facts, and the patterns shared between different instances.We report our empirical study on applying Neural Reasoner to the Question Answer task defined in [8], and compare it against state-of-the-art neural models [9,5].bAbI is a synthetic question and answering dataset. It contains 20 tasks, and each of them is composed of a set of facts, a question and followed by an answer which is mostly a single word. For most of the time, only a subset of facts are relevant to the given question. Two versions of the data are available, one has 1K training instances per task and the other has 10K instances per task, while the testing set are the same for the two versions. We select the two most challenging tasks (among the 20 tasks in [8] ) Positional Reasoning and Path Finding, to test the reasoning ability of Neural Reasoner. Positional Reasoning task tests model's spatial reasoning ability, while Path Finding task, first proposed in [1] tests the ability to reason the correct path between objects based on natural language instructions. In Table 1, we give an instance of each task.In our experiments, we actually used a simplified version of Neural Reasoner . In the version• we choose to keep the representation un-updated on each layer, e.g.,This choice pushes the update q   Table 1: Samples of the two tasks: path finding (upper panel) and positional reasoning (lower panel), with facts, questions and given answers (following each question). For each panel, we first list facts and then question that one needs to answer based on the given facts. On Task I, the answer to the first question is south, east, standing for going south first and then east, obtained based on fact 2 and 4.• we use only two layers, i.e., L = 2, for the relatively simple task in the experiments.Our model was trained with the standard back-propagation (BP) aiming to maximize the likelihood of correct answers. All the parameters including the word-embeddings were initialized by randomly sampling from a uniform distribution [-0.1, 0.1]. No momentum and weight decay was used. We trained all the tasks for 200 epochs with stochastic gradient descent and the gradients which had 2 norm larger than 40 were clipped, learning rate being controlled by AdaDelta [10]. For multi-task learning, different mixture ratios were tried, from 0.1 to 0.9.We compare Neural Reasoner with the following three neural reasoning models: 1)Memory Network, including the one with step-by-step supervision [9](denoted as Memory Net-Step) and the end-to-end version [6] (denoted as Memory Net-N2N), and 2) Dynamic Memory Network, proposed in [5], also with step-by-step supervision. In Table 2, we report the performance of a particular case of Neural Reasoner with 1) two reasoning layers, 2) 2-layer DNNs as the interaction modules in each reasoning layer, and 3) auxiliary task of recovering the original question and facts. The results are compared against three neural competitors. We have the following observations.• The proposed Neural Reasoner performs significantly better than Memory Net-N2N, especially with more training data.• Although not a fair comparison to our model, Neural Reasoner is actually better than Memory Net-N2N and Dynamic Memory Net on Positional Reasoning (1K) &amp; (10K) as well as Path Finding (10K), with about 20% margin on both tasks with 10K training instances.Step-by-   [9], [6] and [5].Please note that the results of Neural Reasoner reported in Table 2 are not based on architectures specifically tuned for the tasks. As a matter of fact, with more complicated models (more reasoning layers and deeper interaction modules), we can achieve even better results on large datasets (e.g., over 98% accuracy on Path Finding with 10K instances). We will however leave the discussion on different architectural variants to the next section.This section is devoted to the study of architectural variants of Neural Reasoner. More specifically, we consider the variations in 1)the number of reasoning layers, 2) the depth of the interaction DNN, and 3) the auxiliary tasks, with results summarized by Table 3. We have the following observations:• Auxiliary tasks are essential to the efficacy of Neural Reasoner, without which the performances of Neural Reasoner drop dramatically. The reason, as we conjecture in Section 4, is that the reasoning task alone cannot give enough supervision for learning accurate word vectors and parameters of the RNN encoder. We note that Neural Reasoner can still outperform Memory Net (N2N) with 10K data on both tasks.• Neural Reasoner with shallow architectures, more specifically two reasoning lay- ers and 1-layer DNN, apparently can benefit from the auxiliary learning of recovering abstract forms on small datasets (1K on both tasks). However, with deeper architec- tures or more training data, the improvement over that of recovering original sentences become smaller, despite the extra information it utilizes.• When larger training datasets are available, Neural Reasoner appears to prefer rela- tively deeper architectures. More importantly, although both tasks require two reason- ing steps, the performance does not deteriorate with three reasoning layers. On both  tasks, with 10K training instances, Neural Reasoner with three reasoning layers and 3-layer DNN can achieve over 98% accuracy.We have proposed Neural Reasoner, a framework for neural network-based reasoning over natural language sentences. Neural Reasoner is flexible, powerful, and language indepedent. Our empirical studies show that Neural Reasoner can dramatically improve upon existing neural reasoning systems on two difficult artificial tasks proposed in [9]. For future work, we will explore 1) tasks with higher difficulty and reasoning depth, e.g., tasks which require a large number of supporting facts and facts with complex intrinsic structures, 2) the common structure in different but similar reasoning tasks (e.g., multiple tasks all with general questions), and 3) automatic selection of the reasoning architecture, for example, determining when to stop the reasoning based on the data.
